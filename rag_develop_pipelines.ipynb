{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d8c47802-b138-431f-995c-5000e4113b29",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import sys\n",
    "import llama_index.core\n",
    "import nest_asyncio\n",
    "\n",
    "nest_asyncio.apply()\n",
    "logging.basicConfig(stream=sys.stdout, level=logging.INFO)\n",
    "llama_index.core.set_global_handler(\"simple\")\n",
    "\n",
    "from llama_index.core.callbacks import (\n",
    "    CallbackManager, TokenCountingHandler,\n",
    "    LlamaDebugHandler, CBEventType, CBEvent\n",
    ")\n",
    "from llama_index.llms.openai import OpenAI\n",
    "from llama_index.embeddings.openai import OpenAIEmbedding\n",
    "from llama_index.core.prompts import PromptTemplate\n",
    "from llama_index.core import (\n",
    "    Settings,\n",
    "    VectorStoreIndex, \n",
    "    SummaryIndex,\n",
    "    StorageContext,\n",
    "    QueryBundle\n",
    ")\n",
    "from llama_index.core.query_engine import RetrieverQueryEngine\n",
    "from llama_index.core.retrievers import VectorIndexAutoRetriever\n",
    "from llama_index.core import get_response_synthesizer\n",
    "from llama_index.core.vector_stores.types import MetadataInfo, VectorStoreInfo\n",
    "from llama_index.core.tools import QueryEngineTool, ToolMetadata\n",
    "import tiktoken\n",
    "import index_utils\n",
    "import chromadb\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4373ec28-5777-41b0-a149-dbb947fb28b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load models and setup callback handler\n",
    "Settings.llm = OpenAI(model=\"gpt-4o-mini\")\n",
    "Settings.embed_model = OpenAIEmbedding(model=\"text-embedding-ada-002\")\n",
    "\n",
    "# callback setup\n",
    "token_counter = TokenCountingHandler(\n",
    "    tokenizer=tiktoken.encoding_for_model(\"gpt-4o-mini\").encode,\n",
    "    verbose=True\n",
    ")\n",
    "llama_debug = LlamaDebugHandler(print_trace_on_end=True)\n",
    "Settings.callback_manager = CallbackManager([token_counter, llama_debug])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d51a9ff2-8d55-44ff-a701-67a807cf917f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:chromadb.telemetry.product.posthog:Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.\n",
      "Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.\n"
     ]
    }
   ],
   "source": [
    "chroma_client = chromadb.PersistentClient(path=\"./chroma_db\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "72aa84b7-6372-4f75-a90f-51d9d6de8f17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Collection(id=1a8bc10a-6620-41d3-97b4-3eebff9b6404, name=in_10_minutes_this_room_will_explode_ts5_scenes_description),\n",
       " Collection(id=358cc788-b408-41a2-84aa-0330aa076966, name=in_10_minutes_this_room_will_explode_transcript_spc_2),\n",
       " Collection(id=e4cce165-5ee1-4c94-b8b9-95d55ddc74a7, name=in_10_minutes_this_room_will_explode_transcript_spc_1)]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chroma_client.list_collections()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "293b9bf7-484f-432c-990c-f18a3a089b3d",
   "metadata": {},
   "source": [
    "## Indexing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1998c404-f28a-4647-bf2f-74a9456d71ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reindexing False\n",
      "Loading index from vector store\n",
      "**********\n",
      "Trace: index_construction\n",
      "**********\n"
     ]
    }
   ],
   "source": [
    "transcript_index = index_utils.get_transcipt_index(\n",
    "    transcript_path=\"./data/audio_transcripts/in_10_minutes_this_room_will_explode.json\",\n",
    "    segs_per_chunk=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6b3af06b-9855-417a-9ad1-13e686bb8015",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating index from vector store\n",
      "**********\n",
      "Trace: index_construction\n",
      "**********\n"
     ]
    }
   ],
   "source": [
    "scene_index = index_utils.get_scene_index(\n",
    "    video_descriptions_path=\"./data/desciptions/in_10_minutes_this_room_will_explode_ts5.json\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89f47571-1aa3-4565-a60f-ac83e34082cf",
   "metadata": {},
   "source": [
    "### Auto retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "cba9b7e1-ee7f-4297-bcf3-c77329710640",
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_store_info = VectorStoreInfo(\n",
    "    content_info=\"Video entertainment content\",\n",
    "    metadata_info=[\n",
    "        MetadataInfo(\n",
    "            name=\"start\",\n",
    "            type=\"float\",\n",
    "            description=(\n",
    "                \"Start time of a shot in seconds\"\n",
    "            ),\n",
    "        ),\n",
    "        MetadataInfo(\n",
    "            name=\"end\",\n",
    "            type=\"float\",\n",
    "            description=(\n",
    "                \"End time of a shot in seconds\"\n",
    "            ),\n",
    "        ),\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "14a902c9-9df5-4cf2-8e32-206bd3252a63",
   "metadata": {},
   "outputs": [],
   "source": [
    "scene_retriever = VectorIndexAutoRetriever(\n",
    "    scene_index, \n",
    "    vector_store_info=vector_store_info,\n",
    "    similarity_top_k=5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "3b202d74-7585-49b5-bb1d-162472f7f467",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:llama_index.core.indices.vector_store.retrievers.auto_retriever.auto_retriever:Using query str: What happened in the video\n",
      "Using query str: What happened in the video\n",
      "INFO:llama_index.core.indices.vector_store.retrievers.auto_retriever.auto_retriever:Using filters: [('start', '>=', 0), ('end', '<=', 180)]\n",
      "Using filters: [('start', '>=', 0), ('end', '<=', 180)]\n",
      "INFO:llama_index.core.indices.vector_store.retrievers.auto_retriever.auto_retriever:Using top_k: 5\n",
      "Using top_k: 5\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"
     ]
    }
   ],
   "source": [
    "%%capture\n",
    "query = \"What happened in the first 3 minutes of the video?\"\n",
    "query_bundle = QueryBundle(query)\n",
    "retrieved_nodes = scene_retriever.retrieve(query_bundle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "02f18b87-c895-4415-a2fc-6436e2d36cb3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: What happened in the first 3 minutes of the video?\n",
      "Retrieved nodes:\n",
      "{\n",
      "  \"start\": 74,\n",
      "  \"end\": 75,\n",
      "  \"content type\": \"scene description\"\n",
      "}\n",
      "================================================================================\n",
      "{\n",
      "  \"start\": 34,\n",
      "  \"end\": 35,\n",
      "  \"content type\": \"scene description\"\n",
      "}\n",
      "================================================================================\n",
      "{\n",
      "  \"start\": 129,\n",
      "  \"end\": 130,\n",
      "  \"content type\": \"scene description\"\n",
      "}\n",
      "================================================================================\n",
      "{\n",
      "  \"start\": 104,\n",
      "  \"end\": 105,\n",
      "  \"content type\": \"scene description\"\n",
      "}\n",
      "================================================================================\n",
      "{\n",
      "  \"start\": 164,\n",
      "  \"end\": 165,\n",
      "  \"content type\": \"scene description\"\n",
      "}\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"Question:\", query)\n",
    "print(\"Retrieved nodes:\")\n",
    "for idx, node in enumerate(retrieved_nodes):\n",
    "    # print(node.text)\n",
    "    print(json.dumps(node.metadata, indent=2))\n",
    "    print(\"==\"*40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "54e6a7b8-624f-4f65-bbde-7099f26be684",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define response synthesizer\n",
    "response_synthesizer = get_response_synthesizer(response_mode=\"tree_summarize\")\n",
    "\n",
    "# assemble query engine\n",
    "scene_summary_engine = RetrieverQueryEngine(\n",
    "    retriever=scene_retriever,\n",
    "    response_synthesizer=response_synthesizer,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "6ca81860-84c4-4234-9efa-e496b54916c7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "LLM Prompt Token Usage: 1287\n",
      "LLM Completion Token Usage: 59\n",
      "** Messages: **\n",
      "user: Your goal is to structure the user's query to match the request schema provided below.\n",
      "\n",
      "<< Structured Request Schema >>\n",
      "When responding use a markdown code snippet with a JSON object formatted in the following schema:\n",
      "\n",
      "{\n",
      "    \"title\": \"VectorStoreQuerySpec\",\n",
      "    \"description\": \"Schema for a structured request for vector store\\n(i.e. to be converted to a VectorStoreQuery).\\n\\nCurrently only used by VectorIndexAutoRetriever.\",\n",
      "    \"type\": \"object\",\n",
      "    \"properties\": {\n",
      "        \"query\": {\n",
      "            \"title\": \"Query\",\n",
      "            \"type\": \"string\"\n",
      "        },\n",
      "        \"filters\": {\n",
      "            \"title\": \"Filters\",\n",
      "            \"type\": \"array\",\n",
      "            \"items\": {\n",
      "                \"$ref\": \"#/definitions/MetadataFilter\"\n",
      "            }\n",
      "        },\n",
      "        \"top_k\": {\n",
      "            \"title\": \"Top K\",\n",
      "            \"type\": \"integer\"\n",
      "        }\n",
      "    },\n",
      "    \"required\": [\n",
      "        \"query\",\n",
      "        \"filters\"\n",
      "    ],\n",
      "    \"definitions\": {\n",
      "        \"FilterOperator\": {\n",
      "            \"title\": \"FilterOperator\",\n",
      "            \"description\": \"Vector store filter operator.\",\n",
      "            \"enum\": [\n",
      "                \"==\",\n",
      "                \">\",\n",
      "                \"<\",\n",
      "                \"!=\",\n",
      "                \">=\",\n",
      "                \"<=\",\n",
      "                \"in\",\n",
      "                \"nin\",\n",
      "                \"any\",\n",
      "                \"all\",\n",
      "                \"text_match\",\n",
      "                \"contains\"\n",
      "            ],\n",
      "            \"type\": \"string\"\n",
      "        },\n",
      "        \"MetadataFilter\": {\n",
      "            \"title\": \"MetadataFilter\",\n",
      "            \"description\": \"Comprehensive metadata filter for vector stores to support more operators.\\n\\nValue uses Strict* types, as int, float and str are compatible types and were all\\nconverted to string before.\\n\\nSee: https://docs.pydantic.dev/latest/usage/types/#strict-types\",\n",
      "            \"type\": \"object\",\n",
      "            \"properties\": {\n",
      "                \"key\": {\n",
      "                    \"title\": \"Key\",\n",
      "                    \"type\": \"string\"\n",
      "                },\n",
      "                \"value\": {\n",
      "                    \"title\": \"Value\",\n",
      "                    \"anyOf\": [\n",
      "                        {\n",
      "                            \"type\": \"integer\"\n",
      "                        },\n",
      "                        {\n",
      "                            \"type\": \"number\"\n",
      "                        },\n",
      "                        {\n",
      "                            \"type\": \"string\"\n",
      "                        },\n",
      "                        {\n",
      "                            \"type\": \"array\",\n",
      "                            \"items\": {\n",
      "                                \"type\": \"string\"\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"type\": \"array\",\n",
      "                            \"items\": {\n",
      "                                \"type\": \"number\"\n",
      "                            }\n",
      "                        },\n",
      "                        {\n",
      "                            \"type\": \"array\",\n",
      "                            \"items\": {\n",
      "                                \"type\": \"integer\"\n",
      "                            }\n",
      "                        }\n",
      "                    ]\n",
      "                },\n",
      "                \"operator\": {\n",
      "                    \"default\": \"==\",\n",
      "                    \"allOf\": [\n",
      "                        {\n",
      "                            \"$ref\": \"#/definitions/FilterOperator\"\n",
      "                        }\n",
      "                    ]\n",
      "                }\n",
      "            },\n",
      "            \"required\": [\n",
      "                \"key\",\n",
      "                \"value\"\n",
      "            ]\n",
      "        }\n",
      "    }\n",
      "}\n",
      "\n",
      "The query string should contain only text that is expected to match the contents of documents. Any conditions in the filter should not be mentioned in the query as well.\n",
      "\n",
      "Make sure that filters only refer to attributes that exist in the data source.\n",
      "Make sure that filters take into account the descriptions of attributes.\n",
      "Make sure that filters are only used as needed. If there are no filters that should be applied return [] for the filter value.\n",
      "If the user's query explicitly mentions number of documents to retrieve, set top_k to that number, otherwise do not set top_k.\n",
      "\n",
      "<< Example 1. >>\n",
      "Data Source:\n",
      "```json\n",
      "{\n",
      "    \"metadata_info\": [\n",
      "        {\n",
      "            \"name\": \"artist\",\n",
      "            \"type\": \"str\",\n",
      "            \"description\": \"Name of the song artist\"\n",
      "        },\n",
      "        {\n",
      "            \"name\": \"genre\",\n",
      "            \"type\": \"str\",\n",
      "            \"description\": \"The song genre, one of \\\"pop\\\", \\\"rock\\\" or \\\"rap\\\"\"\n",
      "        }\n",
      "    ],\n",
      "    \"content_info\": \"Lyrics of a song\"\n",
      "}\n",
      "```\n",
      "\n",
      "User Query:\n",
      "What are songs by Taylor Swift or Katy Perry in the dance pop genre\n",
      "\n",
      "Structured Request:\n",
      "```json\n",
      "{\"query\": \"teenager love\", \"filters\": [{\"key\": \"artist\", \"value\": \"Taylor Swift\", \"operator\": \"==\"}, {\"key\": \"artist\", \"value\": \"Katy Perry\", \"operator\": \"==\"}, {\"key\": \"genre\", \"value\": \"pop\", \"operator\": \"==\"}], \"top_k\": null}\n",
      "\n",
      "\n",
      "<< Example 2. >>\n",
      "Data Source:\n",
      "```json\n",
      "{\n",
      "    \"metadata_info\": [\n",
      "        {\n",
      "            \"name\": \"author\",\n",
      "            \"type\": \"str\",\n",
      "            \"description\": \"Author name\"\n",
      "        },\n",
      "        {\n",
      "            \"name\": \"book_title\",\n",
      "            \"type\": \"str\",\n",
      "            \"description\": \"Book title\"\n",
      "        },\n",
      "        {\n",
      "            \"name\": \"year\",\n",
      "            \"type\": \"int\",\n",
      "            \"description\": \"Year Published\"\n",
      "        },\n",
      "        {\n",
      "            \"name\": \"pages\",\n",
      "            \"type\": \"int\",\n",
      "            \"description\": \"Number of pages\"\n",
      "        },\n",
      "        {\n",
      "            \"name\": \"summary\",\n",
      "            \"type\": \"str\",\n",
      "            \"description\": \"A short summary of the book\"\n",
      "        }\n",
      "    ],\n",
      "    \"content_info\": \"Classic literature\"\n",
      "}\n",
      "```\n",
      "\n",
      "User Query:\n",
      "What are some books by Jane Austen published after 1813 that explore the theme of marriage for social standing?\n",
      "\n",
      "Structured Request:\n",
      "```json\n",
      "{\"query\": \"Books related to theme of marriage for social standing\", \"filters\": [{\"key\": \"year\", \"value\": \"1813\", \"operator\": \">\"}, {\"key\": \"author\", \"value\": \"Jane Austen\", \"operator\": \"==\"}], \"top_k\": null}\n",
      "\n",
      "```\n",
      "\n",
      "<< Example 3. >>\n",
      "Data Source:\n",
      "```json\n",
      "{\n",
      "    \"metadata_info\": [\n",
      "        {\n",
      "            \"name\": \"start\",\n",
      "            \"type\": \"float\",\n",
      "            \"description\": \"Start time of a shot in seconds\"\n",
      "        },\n",
      "        {\n",
      "            \"name\": \"end\",\n",
      "            \"type\": \"float\",\n",
      "            \"description\": \"End time of a shot in seconds\"\n",
      "        }\n",
      "    ],\n",
      "    \"content_info\": \"Video entertainment content\"\n",
      "}\n",
      "```\n",
      "\n",
      "User Query:\n",
      "What happened in the first 3 minutes of the video?\n",
      "\n",
      "Structured Request:\n",
      "\n",
      "**************************************************\n",
      "** Response: **\n",
      "assistant: ```json\n",
      "{\"query\": \"What happened in the video\", \"filters\": [{\"key\": \"start\", \"value\": 0, \"operator\": \">=\"}, {\"key\": \"end\", \"value\": 180, \"operator\": \"<=\"}], \"top_k\": null}\n",
      "```\n",
      "**************************************************\n",
      "\n",
      "\n",
      "INFO:llama_index.core.indices.vector_store.retrievers.auto_retriever.auto_retriever:Using query str: What happened in the video\n",
      "Using query str: What happened in the video\n",
      "INFO:llama_index.core.indices.vector_store.retrievers.auto_retriever.auto_retriever:Using filters: [('start', '>=', 0), ('end', '<=', 180)]\n",
      "Using filters: [('start', '>=', 0), ('end', '<=', 180)]\n",
      "INFO:llama_index.core.indices.vector_store.retrievers.auto_retriever.auto_retriever:Using top_k: 5\n",
      "Using top_k: 5\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Embedding Token Usage: 5\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "LLM Prompt Token Usage: 819\n",
      "LLM Completion Token Usage: 150\n",
      "** Messages: **\n",
      "system: You are an expert Q&A system that is trusted around the world.\n",
      "Always answer the query using the provided context information, and not prior knowledge.\n",
      "Some rules to follow:\n",
      "1. Never directly reference the given context in your answer.\n",
      "2. Avoid statements like 'Based on the context, ...' or 'The context information ...' or anything along those lines.\n",
      "user: Context information from multiple sources is below.\n",
      "---------------------\n",
      "start: 74\n",
      "end: 75\n",
      "content type: scene description\n",
      "\n",
      "In this scene, two young men are positioned on a metal structure, likely part of a game or challenge setup. They appear to be excited and engaged, with one man wearing a white hoodie and the other in a blue sweatshirt. The background features bright lighting, and a digital timer shows 08:46, indicating a countdown. A label in the corner reads \"FLOOR 5,\" suggesting they are on a specific level of a multi-tiered challenge. The atmosphere is energetic and competitive, with both characters actively participating in the moment.\n",
      "\n",
      "start: 34\n",
      "end: 35\n",
      "content type: scene description\n",
      "\n",
      "The scene captures two individuals on a platform high above the ground, with a large digital countdown timer displaying \"09:26\" prominently in the corner. One person, wearing a blue hoodie and shorts, appears animated and engaged, while the other, dressed in a white sweatshirt, is also participating enthusiastically. A camera operator, positioned nearby, is filming the action, adding to the dynamic atmosphere. The setting suggests a high-energy event, possibly a challenge or competition, with bright lighting illuminating the scene against a dark backdrop. The mood is lively and intense, emphasizing excitement and urgency.\n",
      "\n",
      "start: 129\n",
      "end: 130\n",
      "content type: scene description\n",
      "\n",
      "The scene takes place in a brightly lit, modern studio with a minimalist design. In the foreground, a man wearing a brown leather jacket watches intently through a glass wall. He gestures with one hand, possibly encouraging or signaling to someone inside the room. \n",
      "\n",
      "Inside the glass enclosure, another man in a blue shirt is suspended from a harness, reaching for a target while hanging from a set of ropes. A large digital timer displays \"07:51,\" indicating the time remaining for the challenge. The atmosphere is tense and competitive, highlighting the urgency of the task at hand. A smaller inset shows a close-up of the man in the harness, emphasizing the action and stakes involved.\n",
      "\n",
      "start: 104\n",
      "end: 105\n",
      "content type: scene description\n",
      "\n",
      "In this scene, two individuals are standing on a platform, observing a third person who is hanging from a rope in a brightly lit, modern environment. The setting appears to be a game or challenge arena, with a large digital timer displaying \"08:16\" prominently in the corner. The person on the rope is dressed in a blue outfit, while the observers are wearing hooded sweatshirts, one in light gray and the other in blue. The atmosphere is tense and competitive, suggesting a race against time. A small inset shows a closer view of the person on the rope, indicating they are on the fourth floor of the challenge setup.\n",
      "\n",
      "start: 164\n",
      "end: 165\n",
      "content type: scene description\n",
      "\n",
      "The scene depicts a tense moment in an obstacle course challenge. A bald contestant, dressed in a bright blue long-sleeve shirt and black pants, is navigating a rocky terrain. He is positioned near a large, gray boulder that appears to be suspended by ropes, suggesting it could roll down the slope at any moment. The background features a jungle-like setting with greenery and stone walls, enhancing the adventurous atmosphere. A timer in the upper left corner shows 07:16, indicating the remaining time for the challenge. A smaller inset image shows the contestant from a different angle, emphasizing the urgency of the situation.\n",
      "---------------------\n",
      "Given the information from multiple sources and not prior knowledge, answer the query.\n",
      "Query: What happened in the first 3 minutes of the video?\n",
      "Answer: \n",
      "**************************************************\n",
      "** Response: **\n",
      "assistant: In the initial moments of the video, two young men are seen on a metal structure, likely part of a game or challenge, displaying excitement and engagement. One is in a white hoodie and the other in a blue sweatshirt, with a digital timer showing a countdown. The atmosphere is energetic and competitive. Shortly after, the scene shifts to a high platform where the same individuals are animatedly participating, with a large digital countdown timer indicating urgency. A camera operator captures the action, contributing to the lively environment. The focus then transitions to a modern studio where a man in a brown leather jacket observes a contestant suspended from a harness, reaching for a target, with a timer displaying the remaining challenge time. The tension and competitive spirit are palpable throughout these scenes.\n",
      "**************************************************\n",
      "\n",
      "\n",
      "**********\n",
      "Trace: query\n",
      "    |_query -> 4.781794 seconds\n",
      "      |_retrieve -> 1.749323 seconds\n",
      "        |_templating -> 2.5e-05 seconds\n",
      "        |_llm -> 1.314395 seconds\n",
      "      |_synthesize -> 3.031614 seconds\n",
      "        |_templating -> 2e-05 seconds\n",
      "        |_llm -> 3.027303 seconds\n",
      "**********\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Response(response='In the initial moments of the video, two young men are seen on a metal structure, likely part of a game or challenge, displaying excitement and engagement. One is in a white hoodie and the other in a blue sweatshirt, with a digital timer showing a countdown. The atmosphere is energetic and competitive. Shortly after, the scene shifts to a high platform where the same individuals are animatedly participating, with a large digital countdown timer indicating urgency. A camera operator captures the action, contributing to the lively environment. The focus then transitions to a modern studio where a man in a brown leather jacket observes a contestant suspended from a harness, reaching for a target, with a timer displaying the remaining challenge time. The tension and competitive spirit are palpable throughout these scenes.', source_nodes=[NodeWithScore(node=TextNode(id_='39e6cfe1-4afe-4af6-8226-2af6235ec8ee', embedding=None, metadata={'start': 74, 'end': 75, 'content type': 'scene description'}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, text='In this scene, two young men are positioned on a metal structure, likely part of a game or challenge setup. They appear to be excited and engaged, with one man wearing a white hoodie and the other in a blue sweatshirt. The background features bright lighting, and a digital timer shows 08:46, indicating a countdown. A label in the corner reads \"FLOOR 5,\" suggesting they are on a specific level of a multi-tiered challenge. The atmosphere is energetic and competitive, with both characters actively participating in the moment.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), score=0.6708569015870067), NodeWithScore(node=TextNode(id_='3fd88a14-90a9-482c-8765-b0d5129cb185', embedding=None, metadata={'start': 34, 'end': 35, 'content type': 'scene description'}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, text='The scene captures two individuals on a platform high above the ground, with a large digital countdown timer displaying \"09:26\" prominently in the corner. One person, wearing a blue hoodie and shorts, appears animated and engaged, while the other, dressed in a white sweatshirt, is also participating enthusiastically. A camera operator, positioned nearby, is filming the action, adding to the dynamic atmosphere. The setting suggests a high-energy event, possibly a challenge or competition, with bright lighting illuminating the scene against a dark backdrop. The mood is lively and intense, emphasizing excitement and urgency.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), score=0.6686906760554067), NodeWithScore(node=TextNode(id_='f8cef540-7283-4fcb-a804-bfa172844f20', embedding=None, metadata={'start': 129, 'end': 130, 'content type': 'scene description'}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, text='The scene takes place in a brightly lit, modern studio with a minimalist design. In the foreground, a man wearing a brown leather jacket watches intently through a glass wall. He gestures with one hand, possibly encouraging or signaling to someone inside the room. \\n\\nInside the glass enclosure, another man in a blue shirt is suspended from a harness, reaching for a target while hanging from a set of ropes. A large digital timer displays \"07:51,\" indicating the time remaining for the challenge. The atmosphere is tense and competitive, highlighting the urgency of the task at hand. A smaller inset shows a close-up of the man in the harness, emphasizing the action and stakes involved.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), score=0.6659693075969885), NodeWithScore(node=TextNode(id_='6ac25436-c64e-483c-b15b-e075086132bf', embedding=None, metadata={'start': 104, 'end': 105, 'content type': 'scene description'}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, text='In this scene, two individuals are standing on a platform, observing a third person who is hanging from a rope in a brightly lit, modern environment. The setting appears to be a game or challenge arena, with a large digital timer displaying \"08:16\" prominently in the corner. The person on the rope is dressed in a blue outfit, while the observers are wearing hooded sweatshirts, one in light gray and the other in blue. The atmosphere is tense and competitive, suggesting a race against time. A small inset shows a closer view of the person on the rope, indicating they are on the fourth floor of the challenge setup.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), score=0.6653292379891401), NodeWithScore(node=TextNode(id_='e6a62fe2-6f36-4c80-800a-944fb16f5ab0', embedding=None, metadata={'start': 164, 'end': 165, 'content type': 'scene description'}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, text='The scene depicts a tense moment in an obstacle course challenge. A bald contestant, dressed in a bright blue long-sleeve shirt and black pants, is navigating a rocky terrain. He is positioned near a large, gray boulder that appears to be suspended by ropes, suggesting it could roll down the slope at any moment. The background features a jungle-like setting with greenery and stone walls, enhancing the adventurous atmosphere. A timer in the upper left corner shows 07:16, indicating the remaining time for the challenge. A smaller inset image shows the contestant from a different angle, emphasizing the urgency of the situation.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), score=0.6625016131278059)], metadata={'39e6cfe1-4afe-4af6-8226-2af6235ec8ee': {'start': 74, 'end': 75, 'content type': 'scene description'}, '3fd88a14-90a9-482c-8765-b0d5129cb185': {'start': 34, 'end': 35, 'content type': 'scene description'}, 'f8cef540-7283-4fcb-a804-bfa172844f20': {'start': 129, 'end': 130, 'content type': 'scene description'}, '6ac25436-c64e-483c-b15b-e075086132bf': {'start': 104, 'end': 105, 'content type': 'scene description'}, 'e6a62fe2-6f36-4c80-800a-944fb16f5ab0': {'start': 164, 'end': 165, 'content type': 'scene description'}})"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scene_summary_engine.query(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16d1e05b-3d5f-4f8e-b0ec-59ffef9664ee",
   "metadata": {},
   "source": [
    "## Basic query engines"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35235dde-2d9b-4140-8283-03a7167a4bc5",
   "metadata": {},
   "source": [
    "### Transcript query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "61c2745e-edb1-4678-aa87-e6d558a2e711",
   "metadata": {},
   "outputs": [],
   "source": [
    "transcript_query_engine = transcript_index.as_query_engine(\n",
    "    similarity_top_k=5, \n",
    "    use_async=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "14361f97-2310-49b5-9e6d-4afa4dedfa21",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Embedding Token Usage: 4\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "LLM Prompt Token Usage: 321\n",
      "LLM Completion Token Usage: 8\n",
      "** Messages: **\n",
      "system: You are an expert Q&A system that is trusted around the world.\n",
      "Always answer the query using the provided context information, and not prior knowledge.\n",
      "Some rules to follow:\n",
      "1. Never directly reference the given context in your answer.\n",
      "2. Avoid statements like 'Based on the context, ...' or 'The context information ...' or anything along those lines.\n",
      "user: Context information is below.\n",
      "---------------------\n",
      "start: 188.66000366210938\n",
      "end: 194.66000366210938\n",
      "\n",
      " You're gonna have to hurry. Under seven minutes remain, but for your $250,000, you're gonna have to cut the rope.\n",
      "\n",
      "start: 468.5799865722656\n",
      "end: 470.5799865722656\n",
      "\n",
      " Press that red button or his money will explode.\n",
      "\n",
      "start: 588.3800048828125\n",
      "end: 590.3800048828125\n",
      "\n",
      " and asked what he was going to spend it on.\n",
      "\n",
      "start: 389.260009765625\n",
      "end: 392.260009765625\n",
      "\n",
      " I actually don't help him. Well, let's see if he's smart enough to win the money.\n",
      "\n",
      "start: 18.940000534057617\n",
      "end: 25.579999923706055\n",
      "\n",
      " And press that button before the timer hits zero his money explodes. Oh, he's coming down. Okay. This is our first ever real-time shoot\n",
      "---------------------\n",
      "Given the context information and not prior knowledge, answer the query.\n",
      "Query: what is the prize\n",
      "Answer: \n",
      "**************************************************\n",
      "** Response: **\n",
      "assistant: The prize is $250,000.\n",
      "**************************************************\n",
      "\n",
      "\n",
      "**********\n",
      "Trace: query\n",
      "    |_query -> 1.194668 seconds\n",
      "      |_retrieve -> 0.604539 seconds\n",
      "        |_embedding -> 0.546092 seconds\n",
      "      |_synthesize -> 0.589432 seconds\n",
      "        |_templating -> 3.3e-05 seconds\n",
      "        |_llm -> 0.583451 seconds\n",
      "**********\n"
     ]
    }
   ],
   "source": [
    "test_query = '''what is the prize'''\n",
    "response = transcript_query_engine.query(test_query)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54624735-4938-4bbe-b3c3-aae2cf90ec46",
   "metadata": {},
   "source": [
    "### Video query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "28defa40-349d-43fd-977b-309dcd618774",
   "metadata": {},
   "outputs": [],
   "source": [
    "scene_query_engine = scene_index.as_query_engine(\n",
    "    similarity_top_k=5, \n",
    "    use_async=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2a38d745-eacb-42f9-be0a-005153c6cdb1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Embedding Token Usage: 6\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "LLM Prompt Token Usage: 556\n",
      "LLM Completion Token Usage: 68\n",
      "** Messages: **\n",
      "system: You are an expert Q&A system that is trusted around the world.\n",
      "Always answer the query using the provided context information, and not prior knowledge.\n",
      "Some rules to follow:\n",
      "1. Never directly reference the given context in your answer.\n",
      "2. Avoid statements like 'Based on the context, ...' or 'The context information ...' or anything along those lines.\n",
      "user: Context information is below.\n",
      "---------------------\n",
      "start: 526\n",
      "end: 527\n",
      "file_path: data/scenes/in_10_minutes_this_room_will_explode_ts5/frame_15794.jpg\n",
      "\n",
      "The scene captures a tense moment in a game show setting. Two contestants stand on a vibrant green surface, facing a large, multi-level structure with bright red lights illuminating its interior. A prominent red button is positioned in front of them, suggesting a critical action is required. The countdown timer in the upper left corner shows 1:13, adding urgency to the scene. One contestant appears to be preparing for a task, while the other looks on, both focused and determined. The atmosphere is charged with excitement and anticipation.\n",
      "\n",
      "start: 581\n",
      "end: 582\n",
      "file_path: data/scenes/in_10_minutes_this_room_will_explode_ts5/frame_17433.jpg\n",
      "\n",
      "The scene captures a high-energy moment in a competitive game setting. In the foreground, a contestant in a blue outfit is poised to hit a large, red button, displaying intense focus and determination. Two other participants flank him, one on the left wearing a gray shirt and the other on the right in a black shirt, both appearing engaged in the action. A large scoreboard in the background displays numbers, indicating the game's structure, while a timer counts down from 19 seconds, adding urgency to the scene. The atmosphere is vibrant and competitive, with bright lighting and a green turf-like surface enhancing the excitement.\n",
      "\n",
      "start: 19\n",
      "end: 20\n",
      "file_path: data/scenes/in_10_minutes_this_room_will_explode_ts5/frame_00596.jpg\n",
      "\n",
      "The scene depicts a competitive game setting at night, featuring a large, multi-level structure with numbers \"1,\" \"2,\" and \"3\" illuminated on its sides. A prominent red button is highlighted on the ground, suggesting a key action point for participants. In the background, green laser lights create an energetic atmosphere, while a countdown timer displays \"09:41,\" indicating the time remaining for the challenge. A participant stands to the right, observing the setup, which adds to the tension and excitement of the scene. The overall mood is intense and competitive.\n",
      "---------------------\n",
      "Given the context information and not prior knowledge, answer the query.\n",
      "Query: Tell me about the winning scene\n",
      "Answer: \n",
      "**************************************************\n",
      "** Response: **\n",
      "assistant: The winning scene is not explicitly described in the provided information. However, the scenes depict high-energy moments in a competitive game setting, characterized by contestants facing critical actions, countdown timers, and vibrant atmospheres filled with excitement and anticipation. Each scene highlights the urgency and intensity of the competition, but details about a specific winning moment are not included.\n",
      "**************************************************\n",
      "\n",
      "\n",
      "**********\n",
      "Trace: query\n",
      "    |_query -> 1.865573 seconds\n",
      "      |_retrieve -> 0.510927 seconds\n",
      "        |_embedding -> 0.45968 seconds\n",
      "      |_synthesize -> 1.352617 seconds\n",
      "        |_templating -> 2.6e-05 seconds\n",
      "        |_llm -> 1.341279 seconds\n",
      "**********\n"
     ]
    }
   ],
   "source": [
    "query = \"Tell me about the winning scene\"\n",
    "response = scene_query_engine.query(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0d9a963-2c70-41cd-a310-8c5592badfa8",
   "metadata": {},
   "source": [
    "### Basic tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9e34e16e-15c4-4901-8f04-eb9cee60fa0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "transcipt_tool = QueryEngineTool(\n",
    "    query_engine=transcript_query_engine,\n",
    "    metadata=ToolMetadata(\n",
    "        name=f\"transcript_tool\",\n",
    "        description=(\n",
    "            '''answer questions related to audio transcripts, conversations, spoken content'''\n",
    "        )\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f2868607-f2b6-4f42-a860-1f649f2b9d0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "scene_tool = QueryEngineTool(\n",
    "    query_engine=transcipt_tool,\n",
    "    metadata=ToolMetadata(\n",
    "        name=f\"scene_tool\",\n",
    "        description=(\n",
    "            '''answer questions related to scene description content'''\n",
    "        )\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b6d22de-1493-43ec-a453-00926f065cf2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e2e45575-38f7-4710-9347-637faad4705b",
   "metadata": {},
   "source": [
    "## Advanced query engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7538ff59-9751-429a-b222-8a7a9ec37176",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.postprocessor import SentenceTransformerRerank\n",
    "from llama_index.core.indices.query.query_transform import HyDEQueryTransform\n",
    "from llama_index.core.query_engine import TransformQueryEngine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c58c6b74-3749-4323-a1d4-e446b94c223d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/llm/lib/python3.10/site-packages/sentence_transformers/cross_encoder/CrossEncoder.py:11: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from tqdm.autonotebook import tqdm, trange\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:datasets:PyTorch version 2.3.0+cu118 available.\n",
      "PyTorch version 2.3.0+cu118 available.\n"
     ]
    }
   ],
   "source": [
    "# reranker\n",
    "rerank_postprocessor = SentenceTransformerRerank(\n",
    "    model='models/mxbai-rerank-xsmall-v1',\n",
    "    top_n=5, # number of nodes after re-ranking,\n",
    "    keep_retrieval_score=False,\n",
    "    device=\"cuda:1\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eee6fe96-6b64-4277-9a22-f63aa43d7741",
   "metadata": {},
   "outputs": [],
   "source": [
    "# query transform\n",
    "# hyde = HyDEQueryTransform(include_original=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b4ae6f83-3295-4834-9848-5907b2755f2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "advanced_transcript_query_engine = transcript_index.as_query_engine(\n",
    "    node_postprocessors=[rerank_postprocessor],\n",
    "    similarity_top_k=10, # semantic search nodes\n",
    "    use_async=True\n",
    ")\n",
    "# advanced_transcript_query_engine = TransformQueryEngine(\n",
    "#     transcript_query_engine_rerank, \n",
    "# )\n",
    "\n",
    "\n",
    "advanced_scene_query_engine = scene_index.as_query_engine(\n",
    "    node_postprocessors=[rerank_postprocessor],\n",
    "    similarity_top_k=10, # semantic search nodes\n",
    "    use_async=True\n",
    ")\n",
    "\n",
    "summary_query_engine = scene_index.as_query_engine(\n",
    "    response_mode=\"tree_summarize\",\n",
    "    node_postprocessors=[rerank_postprocessor],\n",
    "    similarity_top_k=10, # semantic search nodes\n",
    "    use_async=True\n",
    ")\n",
    "\n",
    "# advanced_scene_query_engine = TransformQueryEngine(scene_query_engine_rerank, hyde)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0bbaf151-f3a6-4d6f-b2ba-7f6085c98c30",
   "metadata": {},
   "outputs": [],
   "source": [
    "advanced_transcipt_tool = QueryEngineTool(\n",
    "    query_engine=advanced_transcript_query_engine,\n",
    "    metadata=ToolMetadata(\n",
    "        name=f\"transcript_tool\",\n",
    "        description=(\n",
    "            '''answer questions related to audio transcripts, conversations, spoken content'''\n",
    "        )\n",
    "    )\n",
    ")\n",
    "advanced_scene_tool = QueryEngineTool(\n",
    "    query_engine=advanced_scene_query_engine,\n",
    "    metadata=ToolMetadata(\n",
    "        name=f\"scene_tool\",\n",
    "        description=(\n",
    "            '''answer questions related to scene description content'''\n",
    "        )\n",
    "    )\n",
    ")\n",
    "\n",
    "summary_tools = QueryEngineTool(\n",
    "    query_engine=summary_query_engine,\n",
    "    metadata=ToolMetadata(\n",
    "        name=f\"summary_tool\",\n",
    "        description=(\n",
    "            '''summary scenes content, what happened in video'''\n",
    "        )\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5a022a1-2373-43d5-8947-b4e57c31743b",
   "metadata": {},
   "source": [
    "### Test query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "931ecbff-5126-49d3-b07b-ea183fb3181f",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_1 = \"what is the prize\"\n",
    "query_2 = \"Describe the winning scene\"\n",
    "query_3 = \"What happened in the first 3 minutes of the video?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "256c1d58-5743-4567-ba69-25de2b5934c7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Embedding Token Usage: 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  1.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "LLM Prompt Token Usage: 355\n",
      "LLM Completion Token Usage: 8\n",
      "** Messages: **\n",
      "system: You are an expert Q&A system that is trusted around the world.\n",
      "Always answer the query using the provided context information, and not prior knowledge.\n",
      "Some rules to follow:\n",
      "1. Never directly reference the given context in your answer.\n",
      "2. Avoid statements like 'Based on the context, ...' or 'The context information ...' or anything along those lines.\n",
      "user: Context information is below.\n",
      "---------------------\n",
      "start: 389.260009765625\n",
      "end: 392.260009765625\n",
      "content type: spoken content\n",
      "\n",
      " I actually don't help him. Well, let's see if he's smart enough to win the money.\n",
      "\n",
      "start: 584.3800048828125\n",
      "end: 586.3800048828125\n",
      "content type: spoken content\n",
      "\n",
      " And after he won with 19 seconds left,\n",
      "\n",
      "start: 188.66000366210938\n",
      "end: 194.66000366210938\n",
      "content type: spoken content\n",
      "\n",
      " You're gonna have to hurry. Under seven minutes remain, but for your $250,000, you're gonna have to cut the rope.\n",
      "\n",
      "start: 223.77999877929688\n",
      "end: 230.5399932861328\n",
      "content type: spoken content\n",
      "\n",
      " $250,000 because of this stupid rope. Jimmy, why'd you find the swollest man possible at cutting a rope? Darcy, hurry up!\n",
      "\n",
      "start: 310.7799987792969\n",
      "end: 314.7799987792969\n",
      "content type: spoken content\n",
      "\n",
      " but if he accidentally touches a laser, his money will instantly explode.\n",
      "---------------------\n",
      "Given the context information and not prior knowledge, answer the query.\n",
      "Query: what is the prize\n",
      "Answer: \n",
      "**************************************************\n",
      "** Response: **\n",
      "assistant: The prize is $250,000.\n",
      "**************************************************\n",
      "\n",
      "\n",
      "**********\n",
      "Trace: query\n",
      "    |_query -> 2.402371 seconds\n",
      "      |_retrieve -> 0.479115 seconds\n",
      "        |_embedding -> 0.419978 seconds\n",
      "      |_reranking -> 0.978304 seconds\n",
      "      |_synthesize -> 0.943659 seconds\n",
      "        |_templating -> 2.5e-05 seconds\n",
      "        |_llm -> 0.935898 seconds\n",
      "**********\n"
     ]
    }
   ],
   "source": [
    "response = advanced_transcript_query_engine.query(query_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8436a852-d990-4b36-a9b8-3e589ca89102",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The prize is $250,000.'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "92381e99-a643-4f07-860c-3edaefadfafe",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 26.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "** Messages: **\n",
      "system: You are an expert Q&A system that is trusted around the world.\n",
      "Always answer the query using the provided context information, and not prior knowledge.\n",
      "Some rules to follow:\n",
      "1. Never directly reference the given context in your answer.\n",
      "2. Avoid statements like 'Based on the context, ...' or 'The context information ...' or anything along those lines.\n",
      "user: Context information is below.\n",
      "---------------------\n",
      "start: 581\n",
      "end: 582\n",
      "content type: scene description\n",
      "retrieval_score: 0.7426275197976455\n",
      "\n",
      "The scene captures a high-energy moment in a competitive game setting. In the foreground, a contestant in a blue outfit is poised to hit a large, red button, displaying intense focus and determination. Two other participants flank him, one on the left wearing a gray shirt and the other on the right in a black shirt, both appearing engaged in the action. A large scoreboard in the background displays numbers, indicating the game's structure, while a timer counts down from 19 seconds, adding urgency to the scene. The atmosphere is vibrant and competitive, with bright lighting and a green turf-like surface enhancing the excitement.\n",
      "\n",
      "start: 69\n",
      "end: 70\n",
      "content type: scene description\n",
      "retrieval_score: 0.7281237086012395\n",
      "\n",
      "The scene depicts two contestants standing in front of a tall, multi-level structure, which is brightly lit and features large numbers indicating the floors. The structure has various lights and a laser display visible on the second floor. One contestant, wearing a gray sweater, is in the act of throwing something towards the building, while the other, dressed in a black and white shirt, watches intently. A digital timer in the corner shows 8:51, indicating a countdown. The atmosphere is tense and competitive, suggesting a game or challenge setting.\n",
      "\n",
      "start: 526\n",
      "end: 527\n",
      "content type: scene description\n",
      "retrieval_score: 0.7475554756278441\n",
      "\n",
      "The scene captures a tense moment in a game show setting. Two contestants stand on a vibrant green surface, facing a large, multi-level structure with bright red lights illuminating its interior. A prominent red button is positioned in front of them, suggesting a critical action is required. The countdown timer in the upper left corner shows 1:13, adding urgency to the scene. One contestant appears to be preparing for a task, while the other looks on, both focused and determined. The atmosphere is charged with excitement and anticipation.\n",
      "\n",
      "start: 144\n",
      "end: 145\n",
      "content type: scene description\n",
      "retrieval_score: 0.7283615987153016\n",
      "\n",
      "The scene depicts an intense moment in a competitive setting, likely from an obstacle course or game show. A contestant, dressed in a blue shirt and dark pants, is seen climbing a thick rope that extends upward. The background features a jungle-themed environment with lush green foliage and stone walls, enhancing the adventurous atmosphere. A timer in the corner indicates 7 minutes and 36 seconds remaining, suggesting a race against time. The scene conveys a sense of urgency and physical challenge as the contestant strives to reach the next level, marked as \"FLOOR 3.\"\n",
      "\n",
      "start: 556\n",
      "end: 557\n",
      "content type: scene description\n",
      "retrieval_score: 0.746126590892264\n",
      "\n",
      "The scene captures a tense moment in a game show setting. In the foreground, two contestants are positioned near a large, circular platform with glowing red accents. One contestant, wearing a black and white striped sweater, appears anxious, with their hands on their head, while the other, dressed in a dark shirt, gestures animatedly, possibly explaining the next challenge. \n",
      "\n",
      "In the background, a towering structure with multiple floors is illuminated, each level numbered and brightly lit, suggesting a competitive atmosphere. A digital timer in the corner counts down from 44 seconds, adding urgency to the scene. The overall mood is intense and suspenseful, emphasizing the high stakes of the competition.\n",
      "---------------------\n",
      "Given the context information and not prior knowledge, answer the query.\n",
      "Query: Describe the winning scene\n",
      "Answer: \n",
      "**************************************************\n",
      "** Response: **\n",
      "assistant: The winning scene likely features a moment of celebration and triumph, where a contestant or team has successfully completed a challenge or game. The atmosphere would be filled with excitement, possibly with confetti falling and bright lights illuminating the area. The winning contestant might be raising their arms in victory, surrounded by cheering supporters or fellow contestants. A scoreboard could display their winning score, while a timer might indicate the successful completion of the task. The overall mood would be jubilant, highlighting the achievement and the culmination of effort in a competitive setting.\n",
      "**************************************************\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "response = advanced_scene_query_engine.query(query_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "17474769-c7db-476e-893a-66fb260d3f45",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Embedding Token Usage: 12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 28.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "LLM Prompt Token Usage: 737\n",
      "LLM Completion Token Usage: 135\n",
      "** Messages: **\n",
      "system: You are an expert Q&A system that is trusted around the world.\n",
      "Always answer the query using the provided context information, and not prior knowledge.\n",
      "Some rules to follow:\n",
      "1. Never directly reference the given context in your answer.\n",
      "2. Avoid statements like 'Based on the context, ...' or 'The context information ...' or anything along those lines.\n",
      "user: Context information from multiple sources is below.\n",
      "---------------------\n",
      "start: 531\n",
      "end: 532\n",
      "content type: scene description\n",
      "\n",
      "The scene captures a moment from a competitive game show or challenge. A young man with short hair is seen in profile, focused and determined, as he stands on a stage with a dark background. A digital timer in the upper left corner shows 01:08, indicating the time remaining for his task. To the right, a display labeled \"FLOOR 1\" suggests he is at the beginning of a multi-level challenge. The atmosphere is tense, emphasizing the urgency of the situation.\n",
      "\n",
      "start: 392\n",
      "end: 393\n",
      "content type: scene description\n",
      "\n",
      "The scene captures an underwater view of a person in a blue shirt, partially submerged in a bright green pool of water. The individual appears to be moving or swimming, with bubbles surrounding them. A digital timer in the upper left corner shows 3 minutes and 28 seconds remaining. In the bottom right corner, a smaller screen displays a similar image of the person, indicating they are on \"Floor 1.\" The atmosphere suggests a competitive or challenging environment, possibly part of a game or reality show.\n",
      "\n",
      "start: 283\n",
      "end: 284\n",
      "content type: scene description\n",
      "\n",
      "The scene captures a tense moment in a game or challenge setting. Two young men, one in a blue shirt and the other in a white hoodie, are peering over a railing, watching intently. Below them, a third individual in a blue shirt is engaged in an activity within a glass enclosure that resembles a jungle environment, complete with greenery and stone walls. A digital timer in the corner shows 5:17, indicating a countdown. The atmosphere is charged with anticipation, as the participants seem focused on the unfolding event below.\n",
      "\n",
      "start: 308\n",
      "end: 309\n",
      "content type: scene description\n",
      "\n",
      "The scene captures an intense moment in a game or challenge environment. A timer displays 4:52, indicating the remaining time. In the foreground, a participant in a blue shirt is crouched down, seemingly focused on a task on a large white block. The background is filled with vibrant green laser beams crisscrossing the space, creating a visually striking atmosphere. A second individual, possibly an observer or teammate, is visible in the background, watching the action unfold. The floor is scattered with shiny debris, adding to the chaotic yet exciting ambiance of the scene.\n",
      "\n",
      "start: 263\n",
      "end: 264\n",
      "content type: scene description\n",
      "\n",
      "The scene captures a tense moment in a game show setting. A contestant, dressed in black, is bracing for impact as a large object, possibly a ball, is about to crash through the wall of a multi-level structure marked with numbers. The structure is brightly lit, with green laser lights visible inside, adding to the dramatic atmosphere. A timer in the corner shows 5:37, indicating a countdown, while a small inset displays another contestant on the third floor. The ground is covered in green material, suggesting a playful yet chaotic environment.\n",
      "---------------------\n",
      "Given the information from multiple sources and not prior knowledge, answer the query.\n",
      "Query: What happened in the first 3 minutes of the video?\n",
      "Answer: \n",
      "**************************************************\n",
      "** Response: **\n",
      "assistant: In the first 3 minutes of the video, various scenes unfold in a competitive game show or challenge setting. Initially, a young man is seen focused on a task with a timer showing 01:08, indicating urgency. Meanwhile, another scene features a person partially submerged in a bright green pool, swimming and surrounded by bubbles, with a timer displaying 3:28. The atmosphere suggests a competitive environment. Additionally, two young men observe a third individual engaged in an activity within a jungle-like enclosure, with a timer at 5:17, highlighting the anticipation of the unfolding events. Overall, the scenes convey a sense of tension and excitement as participants navigate their challenges.\n",
      "**************************************************\n",
      "\n",
      "\n",
      "**********\n",
      "Trace: query\n",
      "    |_query -> 2.356689 seconds\n",
      "      |_retrieve -> 0.535511 seconds\n",
      "        |_embedding -> 0.488533 seconds\n",
      "      |_reranking -> 0.052654 seconds\n",
      "      |_synthesize -> 1.767165 seconds\n",
      "        |_templating -> 1.9e-05 seconds\n",
      "        |_llm -> 1.751442 seconds\n",
      "**********\n"
     ]
    }
   ],
   "source": [
    "response = summary_query_engine.query(query_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e27b97f-7c35-4a99-a9eb-2ca455f1634d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ea463a44-504c-4298-a39b-3d226bf7c95b",
   "metadata": {},
   "source": [
    "## Agents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12ef597f-ebc9-49ad-aeb5-1f531c37160b",
   "metadata": {},
   "source": [
    "### React Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "cc3fd418-94d4-4348-9632-0c0ea8b005d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.agent import AgentRunner, ReActAgentWorker, ReActAgent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b34173ee-d6da-4feb-ae26-a139c91bdd67",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_context = '''Your are video analysis expert, you can answer question related to poken content or visual scene descriptions.\\\n",
    "Focus on accurately understanding the context, intent, and nuances of the spoken content and scene description content. \\\n",
    "If a query asks for details not mentioned in the content, indicate that the information is not available.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "c27ddf72-fbc0-47a8-adfc-8b1bdaac18e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:llama_index.core.agent.react.formatter:ReActChatFormatter.from_context is deprecated, please use `from_defaults` instead.\n",
      "ReActChatFormatter.from_context is deprecated, please use `from_defaults` instead.\n"
     ]
    }
   ],
   "source": [
    "react_agent = ReActAgent.from_tools(\n",
    "    [transcipt_tool, scene_tool],\n",
    "    context=agent_context,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d93388d2-6bf3-4f01-bd98-fa31025d22ac",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Running step 261b4e5e-d31e-4381-ae4b-c0dddf810916. Step input: What is the prize?\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "LLM Prompt Token Usage: 598\n",
      "LLM Completion Token Usage: 43\n",
      "** Messages: **\n",
      "system: You are designed to help with a variety of tasks, from answering questions to providing summaries to other types of analyses.\n",
      "\n",
      "## Tools\n",
      "\n",
      "You have access to a wide variety of tools. You are responsible for using the tools in any sequence you deem appropriate to complete the task at hand.\n",
      "This may require breaking the task into subtasks and using different tools to complete each subtask.\n",
      "\n",
      "You have access to the following tools:\n",
      "> Tool Name: transcript_tool\n",
      "Tool Description: answer questions related to audio transcripts, conversations, spoken content\n",
      "Tool Args: {\"type\": \"object\", \"properties\": {\"input\": {\"title\": \"Input\", \"type\": \"string\"}}, \"required\": [\"input\"]}\n",
      "\n",
      "> Tool Name: scene_tool\n",
      "Tool Description: answer questions related to scene description content\n",
      "Tool Args: {\"type\": \"object\", \"properties\": {\"input\": {\"title\": \"Input\", \"type\": \"string\"}}, \"required\": [\"input\"]}\n",
      "\n",
      "\n",
      "Here is some context to help you answer the question and plan:\n",
      "Your are video analysis expert, you can answer question related to poken content or visual scene descriptions.Focus on accurately understanding the context, intent, and nuances of the spoken content and scene description content. If a query asks for details not mentioned in the content, indicate that the information is not available.\n",
      "\n",
      "\n",
      "## Output Format\n",
      "\n",
      "Please answer in the same language as the question and use the following format:\n",
      "\n",
      "```\n",
      "Thought: The current language of the user is: (user's language). I need to use a tool to help me answer the question.\n",
      "Action: tool name (one of transcript_tool, scene_tool) if using a tool.\n",
      "Action Input: the input to the tool, in a JSON format representing the kwargs (e.g. {\"input\": \"hello world\", \"num_beams\": 5})\n",
      "```\n",
      "\n",
      "Please ALWAYS start with a Thought.\n",
      "\n",
      "NEVER surround your response with markdown code markers. You may use code markers within your response if you need to.\n",
      "\n",
      "Please use a valid JSON format for the Action Input. Do NOT do this {'input': 'hello world', 'num_beams': 5}.\n",
      "\n",
      "If this format is used, the user will respond in the following format:\n",
      "\n",
      "```\n",
      "Observation: tool response\n",
      "```\n",
      "\n",
      "You should keep repeating the above format till you have enough information to answer the question without using any more tools. At that point, you MUST respond in the one of the following two formats:\n",
      "\n",
      "```\n",
      "Thought: I can answer without using any more tools. I'll use the user's language to answer\n",
      "Answer: [your answer here (In the same language as the user's question)]\n",
      "```\n",
      "\n",
      "```\n",
      "Thought: I cannot answer the question with the provided tools.\n",
      "Answer: [your answer here (In the same language as the user's question)]\n",
      "```\n",
      "\n",
      "## Current Conversation\n",
      "\n",
      "Below is the current conversation consisting of interleaving human and assistant messages.\n",
      "\n",
      "user: What is the prize?\n",
      "**************************************************\n",
      "** Response: **\n",
      "assistant: Thought: The current language of the user is: English. I need to use a tool to help me answer the question.\n",
      "Action: transcript_tool\n",
      "Action Input: {\"input\": \"What is the prize?\"}\n",
      "**************************************************\n",
      "\n",
      "\n",
      "\u001b[1;3;38;5;200mThought: The current language of the user is: English. I need to use a tool to help me answer the question.\n",
      "Action: transcript_tool\n",
      "Action Input: {'input': 'What is the prize?'}\n",
      "\u001b[0mINFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Embedding Token Usage: 5\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "LLM Prompt Token Usage: 308\n",
      "LLM Completion Token Usage: 8\n",
      "** Messages: **\n",
      "system: You are an expert Q&A system that is trusted around the world.\n",
      "Always answer the query using the provided context information, and not prior knowledge.\n",
      "Some rules to follow:\n",
      "1. Never directly reference the given context in your answer.\n",
      "2. Avoid statements like 'Based on the context, ...' or 'The context information ...' or anything along those lines.\n",
      "user: Context information is below.\n",
      "---------------------\n",
      "start: 188.66000366210938\n",
      "end: 194.66000366210938\n",
      "\n",
      " You're gonna have to hurry. Under seven minutes remain, but for your $250,000, you're gonna have to cut the rope.\n",
      "\n",
      "start: 588.3800048828125\n",
      "end: 590.3800048828125\n",
      "\n",
      " and asked what he was going to spend it on.\n",
      "\n",
      "start: 389.260009765625\n",
      "end: 392.260009765625\n",
      "\n",
      " I actually don't help him. Well, let's see if he's smart enough to win the money.\n",
      "\n",
      "start: 489.739990234375\n",
      "end: 492.739990234375\n",
      "\n",
      " All right. The final door. A minute and 50 seconds. All right. What now?\n",
      "\n",
      "start: 468.5799865722656\n",
      "end: 470.5799865722656\n",
      "\n",
      " Press that red button or his money will explode.\n",
      "---------------------\n",
      "Given the context information and not prior knowledge, answer the query.\n",
      "Query: What is the prize?\n",
      "Answer: \n",
      "**************************************************\n",
      "** Response: **\n",
      "assistant: The prize is $250,000.\n",
      "**************************************************\n",
      "\n",
      "\n",
      "\u001b[1;3;34mObservation: The prize is $250,000.\n",
      "\u001b[0m> Running step b70304a3-e15e-4d8d-87a4-06ff49211fe8. Step input: None\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "LLM Prompt Token Usage: 659\n",
      "LLM Completion Token Usage: 29\n",
      "** Messages: **\n",
      "system: You are designed to help with a variety of tasks, from answering questions to providing summaries to other types of analyses.\n",
      "\n",
      "## Tools\n",
      "\n",
      "You have access to a wide variety of tools. You are responsible for using the tools in any sequence you deem appropriate to complete the task at hand.\n",
      "This may require breaking the task into subtasks and using different tools to complete each subtask.\n",
      "\n",
      "You have access to the following tools:\n",
      "> Tool Name: transcript_tool\n",
      "Tool Description: answer questions related to audio transcripts, conversations, spoken content\n",
      "Tool Args: {\"type\": \"object\", \"properties\": {\"input\": {\"title\": \"Input\", \"type\": \"string\"}}, \"required\": [\"input\"]}\n",
      "\n",
      "> Tool Name: scene_tool\n",
      "Tool Description: answer questions related to scene description content\n",
      "Tool Args: {\"type\": \"object\", \"properties\": {\"input\": {\"title\": \"Input\", \"type\": \"string\"}}, \"required\": [\"input\"]}\n",
      "\n",
      "\n",
      "Here is some context to help you answer the question and plan:\n",
      "Your are video analysis expert, you can answer question related to poken content or visual scene descriptions.Focus on accurately understanding the context, intent, and nuances of the spoken content and scene description content. If a query asks for details not mentioned in the content, indicate that the information is not available.\n",
      "\n",
      "\n",
      "## Output Format\n",
      "\n",
      "Please answer in the same language as the question and use the following format:\n",
      "\n",
      "```\n",
      "Thought: The current language of the user is: (user's language). I need to use a tool to help me answer the question.\n",
      "Action: tool name (one of transcript_tool, scene_tool) if using a tool.\n",
      "Action Input: the input to the tool, in a JSON format representing the kwargs (e.g. {\"input\": \"hello world\", \"num_beams\": 5})\n",
      "```\n",
      "\n",
      "Please ALWAYS start with a Thought.\n",
      "\n",
      "NEVER surround your response with markdown code markers. You may use code markers within your response if you need to.\n",
      "\n",
      "Please use a valid JSON format for the Action Input. Do NOT do this {'input': 'hello world', 'num_beams': 5}.\n",
      "\n",
      "If this format is used, the user will respond in the following format:\n",
      "\n",
      "```\n",
      "Observation: tool response\n",
      "```\n",
      "\n",
      "You should keep repeating the above format till you have enough information to answer the question without using any more tools. At that point, you MUST respond in the one of the following two formats:\n",
      "\n",
      "```\n",
      "Thought: I can answer without using any more tools. I'll use the user's language to answer\n",
      "Answer: [your answer here (In the same language as the user's question)]\n",
      "```\n",
      "\n",
      "```\n",
      "Thought: I cannot answer the question with the provided tools.\n",
      "Answer: [your answer here (In the same language as the user's question)]\n",
      "```\n",
      "\n",
      "## Current Conversation\n",
      "\n",
      "Below is the current conversation consisting of interleaving human and assistant messages.\n",
      "\n",
      "user: What is the prize?\n",
      "assistant: Thought: The current language of the user is: English. I need to use a tool to help me answer the question.\n",
      "Action: transcript_tool\n",
      "Action Input: {'input': 'What is the prize?'}\n",
      "user: Observation: The prize is $250,000.\n",
      "**************************************************\n",
      "** Response: **\n",
      "assistant: Thought: I can answer without using any more tools. I'll use the user's language to answer.\n",
      "Answer: The prize is $250,000.\n",
      "**************************************************\n",
      "\n",
      "\n",
      "\u001b[1;3;38;5;200mThought: I can answer without using any more tools. I'll use the user's language to answer.\n",
      "Answer: The prize is $250,000.\n",
      "\u001b[0m**********\n",
      "Trace: chat\n",
      "    |_agent_step -> 3.158805 seconds\n",
      "      |_llm -> 1.043326 seconds\n",
      "      |_function_call -> 1.266722 seconds\n",
      "        |_query -> 1.266376 seconds\n",
      "          |_retrieve -> 0.43491 seconds\n",
      "            |_embedding -> 0.427498 seconds\n",
      "          |_synthesize -> 0.830971 seconds\n",
      "            |_templating -> 1.8e-05 seconds\n",
      "            |_llm -> 0.825273 seconds\n",
      "      |_llm -> 0.84073 seconds\n",
      "**********\n"
     ]
    }
   ],
   "source": [
    "response = react_agent.chat(\"What is the prize?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "3e820de8-ace7-4542-8d7f-507c6deac741",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Running step b4aef6c7-0cd0-4080-8dee-e47c79a7f2f5. Step input: What timestamp the prize is mentioned?\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "LLM Prompt Token Usage: 621\n",
      "LLM Completion Token Usage: 45\n",
      "** Messages: **\n",
      "system: You are designed to help with a variety of tasks, from answering questions to providing summaries to other types of analyses.\n",
      "\n",
      "## Tools\n",
      "\n",
      "You have access to a wide variety of tools. You are responsible for using the tools in any sequence you deem appropriate to complete the task at hand.\n",
      "This may require breaking the task into subtasks and using different tools to complete each subtask.\n",
      "\n",
      "You have access to the following tools:\n",
      "> Tool Name: transcript_tool\n",
      "Tool Description: answer questions related to audio transcripts, conversations, spoken content\n",
      "Tool Args: {\"type\": \"object\", \"properties\": {\"input\": {\"title\": \"Input\", \"type\": \"string\"}}, \"required\": [\"input\"]}\n",
      "\n",
      "> Tool Name: scene_tool\n",
      "Tool Description: answer questions related to scene description content\n",
      "Tool Args: {\"type\": \"object\", \"properties\": {\"input\": {\"title\": \"Input\", \"type\": \"string\"}}, \"required\": [\"input\"]}\n",
      "\n",
      "\n",
      "Here is some context to help you answer the question and plan:\n",
      "Your are video analysis expert, you can answer question related to poken content or visual scene descriptions.Focus on accurately understanding the context, intent, and nuances of the spoken content and scene description content. If a query asks for details not mentioned in the content, indicate that the information is not available.\n",
      "\n",
      "\n",
      "## Output Format\n",
      "\n",
      "Please answer in the same language as the question and use the following format:\n",
      "\n",
      "```\n",
      "Thought: The current language of the user is: (user's language). I need to use a tool to help me answer the question.\n",
      "Action: tool name (one of transcript_tool, scene_tool) if using a tool.\n",
      "Action Input: the input to the tool, in a JSON format representing the kwargs (e.g. {\"input\": \"hello world\", \"num_beams\": 5})\n",
      "```\n",
      "\n",
      "Please ALWAYS start with a Thought.\n",
      "\n",
      "NEVER surround your response with markdown code markers. You may use code markers within your response if you need to.\n",
      "\n",
      "Please use a valid JSON format for the Action Input. Do NOT do this {'input': 'hello world', 'num_beams': 5}.\n",
      "\n",
      "If this format is used, the user will respond in the following format:\n",
      "\n",
      "```\n",
      "Observation: tool response\n",
      "```\n",
      "\n",
      "You should keep repeating the above format till you have enough information to answer the question without using any more tools. At that point, you MUST respond in the one of the following two formats:\n",
      "\n",
      "```\n",
      "Thought: I can answer without using any more tools. I'll use the user's language to answer\n",
      "Answer: [your answer here (In the same language as the user's question)]\n",
      "```\n",
      "\n",
      "```\n",
      "Thought: I cannot answer the question with the provided tools.\n",
      "Answer: [your answer here (In the same language as the user's question)]\n",
      "```\n",
      "\n",
      "## Current Conversation\n",
      "\n",
      "Below is the current conversation consisting of interleaving human and assistant messages.\n",
      "\n",
      "user: What is the prize?\n",
      "assistant: The prize is $250,000.\n",
      "user: What timestamp the prize is mentioned?\n",
      "**************************************************\n",
      "** Response: **\n",
      "assistant: Thought: The current language of the user is: English. I need to use a tool to help me answer the question.\n",
      "Action: transcript_tool\n",
      "Action Input: {\"input\": \"What timestamp the prize is mentioned?\"}\n",
      "**************************************************\n",
      "\n",
      "\n",
      "\u001b[1;3;38;5;200mThought: The current language of the user is: English. I need to use a tool to help me answer the question.\n",
      "Action: transcript_tool\n",
      "Action Input: {'input': 'What timestamp the prize is mentioned?'}\n",
      "\u001b[0mINFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Embedding Token Usage: 7\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "LLM Prompt Token Usage: 302\n",
      "LLM Completion Token Usage: 16\n",
      "** Messages: **\n",
      "system: You are an expert Q&A system that is trusted around the world.\n",
      "Always answer the query using the provided context information, and not prior knowledge.\n",
      "Some rules to follow:\n",
      "1. Never directly reference the given context in your answer.\n",
      "2. Avoid statements like 'Based on the context, ...' or 'The context information ...' or anything along those lines.\n",
      "user: Context information is below.\n",
      "---------------------\n",
      "start: 188.66000366210938\n",
      "end: 194.66000366210938\n",
      "\n",
      " You're gonna have to hurry. Under seven minutes remain, but for your $250,000, you're gonna have to cut the rope.\n",
      "\n",
      "start: 584.3800048828125\n",
      "end: 586.3800048828125\n",
      "\n",
      " And after he won with 19 seconds left,\n",
      "\n",
      "start: 588.3800048828125\n",
      "end: 590.3800048828125\n",
      "\n",
      " and asked what he was going to spend it on.\n",
      "\n",
      "start: 468.5799865722656\n",
      "end: 470.5799865722656\n",
      "\n",
      " Press that red button or his money will explode.\n",
      "\n",
      "start: 464.5799865722656\n",
      "end: 468.5799865722656\n",
      "\n",
      " All right. So he has two minutes and 10 seconds to right over here.\n",
      "---------------------\n",
      "Given the context information and not prior knowledge, answer the query.\n",
      "Query: What timestamp the prize is mentioned?\n",
      "Answer: \n",
      "**************************************************\n",
      "** Response: **\n",
      "assistant: The prize is mentioned at the timestamp 188.66000366210938.\n",
      "**************************************************\n",
      "\n",
      "\n",
      "\u001b[1;3;34mObservation: The prize is mentioned at the timestamp 188.66000366210938.\n",
      "\u001b[0m> Running step b698ce11-56ac-4d2b-887b-4c32fc9bd942. Step input: None\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "LLM Prompt Token Usage: 692\n",
      "LLM Completion Token Usage: 33\n",
      "** Messages: **\n",
      "system: You are designed to help with a variety of tasks, from answering questions to providing summaries to other types of analyses.\n",
      "\n",
      "## Tools\n",
      "\n",
      "You have access to a wide variety of tools. You are responsible for using the tools in any sequence you deem appropriate to complete the task at hand.\n",
      "This may require breaking the task into subtasks and using different tools to complete each subtask.\n",
      "\n",
      "You have access to the following tools:\n",
      "> Tool Name: transcript_tool\n",
      "Tool Description: answer questions related to audio transcripts, conversations, spoken content\n",
      "Tool Args: {\"type\": \"object\", \"properties\": {\"input\": {\"title\": \"Input\", \"type\": \"string\"}}, \"required\": [\"input\"]}\n",
      "\n",
      "> Tool Name: scene_tool\n",
      "Tool Description: answer questions related to scene description content\n",
      "Tool Args: {\"type\": \"object\", \"properties\": {\"input\": {\"title\": \"Input\", \"type\": \"string\"}}, \"required\": [\"input\"]}\n",
      "\n",
      "\n",
      "Here is some context to help you answer the question and plan:\n",
      "Your are video analysis expert, you can answer question related to poken content or visual scene descriptions.Focus on accurately understanding the context, intent, and nuances of the spoken content and scene description content. If a query asks for details not mentioned in the content, indicate that the information is not available.\n",
      "\n",
      "\n",
      "## Output Format\n",
      "\n",
      "Please answer in the same language as the question and use the following format:\n",
      "\n",
      "```\n",
      "Thought: The current language of the user is: (user's language). I need to use a tool to help me answer the question.\n",
      "Action: tool name (one of transcript_tool, scene_tool) if using a tool.\n",
      "Action Input: the input to the tool, in a JSON format representing the kwargs (e.g. {\"input\": \"hello world\", \"num_beams\": 5})\n",
      "```\n",
      "\n",
      "Please ALWAYS start with a Thought.\n",
      "\n",
      "NEVER surround your response with markdown code markers. You may use code markers within your response if you need to.\n",
      "\n",
      "Please use a valid JSON format for the Action Input. Do NOT do this {'input': 'hello world', 'num_beams': 5}.\n",
      "\n",
      "If this format is used, the user will respond in the following format:\n",
      "\n",
      "```\n",
      "Observation: tool response\n",
      "```\n",
      "\n",
      "You should keep repeating the above format till you have enough information to answer the question without using any more tools. At that point, you MUST respond in the one of the following two formats:\n",
      "\n",
      "```\n",
      "Thought: I can answer without using any more tools. I'll use the user's language to answer\n",
      "Answer: [your answer here (In the same language as the user's question)]\n",
      "```\n",
      "\n",
      "```\n",
      "Thought: I cannot answer the question with the provided tools.\n",
      "Answer: [your answer here (In the same language as the user's question)]\n",
      "```\n",
      "\n",
      "## Current Conversation\n",
      "\n",
      "Below is the current conversation consisting of interleaving human and assistant messages.\n",
      "\n",
      "user: What is the prize?\n",
      "assistant: The prize is $250,000.\n",
      "user: What timestamp the prize is mentioned?\n",
      "assistant: Thought: The current language of the user is: English. I need to use a tool to help me answer the question.\n",
      "Action: transcript_tool\n",
      "Action Input: {'input': 'What timestamp the prize is mentioned?'}\n",
      "user: Observation: The prize is mentioned at the timestamp 188.66000366210938.\n",
      "**************************************************\n",
      "** Response: **\n",
      "assistant: Thought: I can answer without using any more tools. I'll use the user's language to answer.\n",
      "Answer: The prize is mentioned at the timestamp 188.66.\n",
      "**************************************************\n",
      "\n",
      "\n",
      "\u001b[1;3;38;5;200mThought: I can answer without using any more tools. I'll use the user's language to answer.\n",
      "Answer: The prize is mentioned at the timestamp 188.66.\n",
      "\u001b[0m**********\n",
      "Trace: chat\n",
      "    |_agent_step -> 3.769005 seconds\n",
      "      |_llm -> 1.343293 seconds\n",
      "      |_function_call -> 1.201603 seconds\n",
      "        |_query -> 1.201247 seconds\n",
      "          |_retrieve -> 0.39284 seconds\n",
      "            |_embedding -> 0.384479 seconds\n",
      "          |_synthesize -> 0.807824 seconds\n",
      "            |_templating -> 1.9e-05 seconds\n",
      "            |_llm -> 0.803662 seconds\n",
      "      |_llm -> 1.211653 seconds\n",
      "**********\n"
     ]
    }
   ],
   "source": [
    "response = react_agent.chat(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "c053db9d-88e1-424f-90a4-8a2c985b8f96",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Running step 932d4c27-465c-4a22-a33b-afe36c448b16. Step input: what happended from first 5 minutes\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "LLM Prompt Token Usage: 749\n",
      "LLM Completion Token Usage: 50\n",
      "** Messages: **\n",
      "system: You are designed to help with a variety of tasks, from answering questions to providing summaries to other types of analyses.\n",
      "\n",
      "## Tools\n",
      "\n",
      "You have access to a wide variety of tools. You are responsible for using the tools in any sequence you deem appropriate to complete the task at hand.\n",
      "This may require breaking the task into subtasks and using different tools to complete each subtask.\n",
      "\n",
      "You have access to the following tools:\n",
      "> Tool Name: transcript_tool\n",
      "Tool Description: answer questions related to audio transcripts, conversations, spoken content\n",
      "Tool Args: {\"type\": \"object\", \"properties\": {\"input\": {\"title\": \"Input\", \"type\": \"string\"}}, \"required\": [\"input\"]}\n",
      "\n",
      "> Tool Name: scene_tool\n",
      "Tool Description: answer questions related to scene description content\n",
      "Tool Args: {\"type\": \"object\", \"properties\": {\"input\": {\"title\": \"Input\", \"type\": \"string\"}}, \"required\": [\"input\"]}\n",
      "\n",
      "\n",
      "Here is some context to help you answer the question and plan:\n",
      "Your are video analysis expert, you can answer question related to poken content or visual scene descriptions.Focus on accurately understanding the context, intent, and nuances of the spoken content and scene description content. If a query asks for details not mentioned in the content, indicate that the information is not available.\n",
      "\n",
      "\n",
      "## Output Format\n",
      "\n",
      "Please answer in the same language as the question and use the following format:\n",
      "\n",
      "```\n",
      "Thought: The current language of the user is: (user's language). I need to use a tool to help me answer the question.\n",
      "Action: tool name (one of transcript_tool, scene_tool) if using a tool.\n",
      "Action Input: the input to the tool, in a JSON format representing the kwargs (e.g. {\"input\": \"hello world\", \"num_beams\": 5})\n",
      "```\n",
      "\n",
      "Please ALWAYS start with a Thought.\n",
      "\n",
      "NEVER surround your response with markdown code markers. You may use code markers within your response if you need to.\n",
      "\n",
      "Please use a valid JSON format for the Action Input. Do NOT do this {'input': 'hello world', 'num_beams': 5}.\n",
      "\n",
      "If this format is used, the user will respond in the following format:\n",
      "\n",
      "```\n",
      "Observation: tool response\n",
      "```\n",
      "\n",
      "You should keep repeating the above format till you have enough information to answer the question without using any more tools. At that point, you MUST respond in the one of the following two formats:\n",
      "\n",
      "```\n",
      "Thought: I can answer without using any more tools. I'll use the user's language to answer\n",
      "Answer: [your answer here (In the same language as the user's question)]\n",
      "```\n",
      "\n",
      "```\n",
      "Thought: I cannot answer the question with the provided tools.\n",
      "Answer: [your answer here (In the same language as the user's question)]\n",
      "```\n",
      "\n",
      "## Current Conversation\n",
      "\n",
      "Below is the current conversation consisting of interleaving human and assistant messages.\n",
      "\n",
      "user: What is the prize?\n",
      "assistant: The prize is $250,000.\n",
      "user: What timestamp the prize is mentioned?\n",
      "assistant: The prize is mentioned at the timestamp 188.66.\n",
      "user: summarize 5 minutes video content\n",
      "assistant: The video features a live segment centered around a character named Darcy, emphasizing the importance of time. It showcases an unbroken shot, indicating that a minute has already passed, and creates a sense of urgency as someone is reminded they have only five minutes left to take action, specifically to stop a crane. The structure of the video is designed to maintain a continuous flow, contrasting with typical editing practices that would cut slow moments.\n",
      "user: what happended from first 5 minutes\n",
      "**************************************************\n",
      "** Response: **\n",
      "assistant: Thought: The current language of the user is: English. I need to use a tool to help me answer the question.\n",
      "Action: transcript_tool\n",
      "Action Input: {\"input\": \"What happened in the first 5 minutes of the video?\"}\n",
      "**************************************************\n",
      "\n",
      "\n",
      "\u001b[1;3;38;5;200mThought: The current language of the user is: English. I need to use a tool to help me answer the question.\n",
      "Action: transcript_tool\n",
      "Action Input: {'input': 'What happened in the first 5 minutes of the video?'}\n",
      "\u001b[0mINFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Embedding Token Usage: 12\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "LLM Prompt Token Usage: 315\n",
      "LLM Completion Token Usage: 55\n",
      "** Messages: **\n",
      "system: You are an expert Q&A system that is trusted around the world.\n",
      "Always answer the query using the provided context information, and not prior knowledge.\n",
      "Some rules to follow:\n",
      "1. Never directly reference the given context in your answer.\n",
      "2. Avoid statements like 'Based on the context, ...' or 'The context information ...' or anything along those lines.\n",
      "user: Context information is below.\n",
      "---------------------\n",
      "start: 295.6199951171875\n",
      "end: 302.6199951171875\n",
      "\n",
      " What? Okay! He has exactly five minutes left! Stop the crane! Stop the crane! Stop the crane! Stop the crane!\n",
      "\n",
      "start: 598.3800048828125\n",
      "end: 600.3800048828125\n",
      "\n",
      " We have to make this video exactly 10 minutes.\n",
      "\n",
      "start: 489.739990234375\n",
      "end: 492.739990234375\n",
      "\n",
      " All right. The final door. A minute and 50 seconds. All right. What now?\n",
      "\n",
      "start: 108.0199966430664\n",
      "end: 110.0199966430664\n",
      "\n",
      " Two minutes has gone by!\n",
      "\n",
      "start: 6.579999923706055\n",
      "end: 11.020000457763672\n",
      "\n",
      " Only man that can stop it is this man in this straight jacket. This video is completely real-time\n",
      "---------------------\n",
      "Given the context information and not prior knowledge, answer the query.\n",
      "Query: What happened in the first 5 minutes of the video?\n",
      "Answer: \n",
      "**************************************************\n",
      "** Response: **\n",
      "assistant: In the first five minutes of the video, there is a sense of urgency as someone is trying to stop a crane, indicating that time is critical. The phrase \"He has exactly five minutes left!\" suggests that there is a countdown or a deadline that needs to be met.\n",
      "**************************************************\n",
      "\n",
      "\n",
      "\u001b[1;3;34mObservation: In the first five minutes of the video, there is a sense of urgency as someone is trying to stop a crane, indicating that time is critical. The phrase \"He has exactly five minutes left!\" suggests that there is a countdown or a deadline that needs to be met.\n",
      "\u001b[0m> Running step 54d3819b-3d01-4347-b462-022548475723. Step input: None\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "LLM Prompt Token Usage: 864\n",
      "LLM Completion Token Usage: 76\n",
      "** Messages: **\n",
      "system: You are designed to help with a variety of tasks, from answering questions to providing summaries to other types of analyses.\n",
      "\n",
      "## Tools\n",
      "\n",
      "You have access to a wide variety of tools. You are responsible for using the tools in any sequence you deem appropriate to complete the task at hand.\n",
      "This may require breaking the task into subtasks and using different tools to complete each subtask.\n",
      "\n",
      "You have access to the following tools:\n",
      "> Tool Name: transcript_tool\n",
      "Tool Description: answer questions related to audio transcripts, conversations, spoken content\n",
      "Tool Args: {\"type\": \"object\", \"properties\": {\"input\": {\"title\": \"Input\", \"type\": \"string\"}}, \"required\": [\"input\"]}\n",
      "\n",
      "> Tool Name: scene_tool\n",
      "Tool Description: answer questions related to scene description content\n",
      "Tool Args: {\"type\": \"object\", \"properties\": {\"input\": {\"title\": \"Input\", \"type\": \"string\"}}, \"required\": [\"input\"]}\n",
      "\n",
      "\n",
      "Here is some context to help you answer the question and plan:\n",
      "Your are video analysis expert, you can answer question related to poken content or visual scene descriptions.Focus on accurately understanding the context, intent, and nuances of the spoken content and scene description content. If a query asks for details not mentioned in the content, indicate that the information is not available.\n",
      "\n",
      "\n",
      "## Output Format\n",
      "\n",
      "Please answer in the same language as the question and use the following format:\n",
      "\n",
      "```\n",
      "Thought: The current language of the user is: (user's language). I need to use a tool to help me answer the question.\n",
      "Action: tool name (one of transcript_tool, scene_tool) if using a tool.\n",
      "Action Input: the input to the tool, in a JSON format representing the kwargs (e.g. {\"input\": \"hello world\", \"num_beams\": 5})\n",
      "```\n",
      "\n",
      "Please ALWAYS start with a Thought.\n",
      "\n",
      "NEVER surround your response with markdown code markers. You may use code markers within your response if you need to.\n",
      "\n",
      "Please use a valid JSON format for the Action Input. Do NOT do this {'input': 'hello world', 'num_beams': 5}.\n",
      "\n",
      "If this format is used, the user will respond in the following format:\n",
      "\n",
      "```\n",
      "Observation: tool response\n",
      "```\n",
      "\n",
      "You should keep repeating the above format till you have enough information to answer the question without using any more tools. At that point, you MUST respond in the one of the following two formats:\n",
      "\n",
      "```\n",
      "Thought: I can answer without using any more tools. I'll use the user's language to answer\n",
      "Answer: [your answer here (In the same language as the user's question)]\n",
      "```\n",
      "\n",
      "```\n",
      "Thought: I cannot answer the question with the provided tools.\n",
      "Answer: [your answer here (In the same language as the user's question)]\n",
      "```\n",
      "\n",
      "## Current Conversation\n",
      "\n",
      "Below is the current conversation consisting of interleaving human and assistant messages.\n",
      "\n",
      "user: What is the prize?\n",
      "assistant: The prize is $250,000.\n",
      "user: What timestamp the prize is mentioned?\n",
      "assistant: The prize is mentioned at the timestamp 188.66.\n",
      "user: summarize 5 minutes video content\n",
      "assistant: The video features a live segment centered around a character named Darcy, emphasizing the importance of time. It showcases an unbroken shot, indicating that a minute has already passed, and creates a sense of urgency as someone is reminded they have only five minutes left to take action, specifically to stop a crane. The structure of the video is designed to maintain a continuous flow, contrasting with typical editing practices that would cut slow moments.\n",
      "user: what happended from first 5 minutes\n",
      "assistant: Thought: The current language of the user is: English. I need to use a tool to help me answer the question.\n",
      "Action: transcript_tool\n",
      "Action Input: {'input': 'What happened in the first 5 minutes of the video?'}\n",
      "user: Observation: In the first five minutes of the video, there is a sense of urgency as someone is trying to stop a crane, indicating that time is critical. The phrase \"He has exactly five minutes left!\" suggests that there is a countdown or a deadline that needs to be met.\n",
      "**************************************************\n",
      "** Response: **\n",
      "assistant: Thought: I can answer without using any more tools. I'll use the user's language to answer.\n",
      "Answer: In the first five minutes of the video, there is a sense of urgency as someone is trying to stop a crane, indicating that time is critical. The phrase \"He has exactly five minutes left!\" suggests that there is a countdown or a deadline that needs to be met.\n",
      "**************************************************\n",
      "\n",
      "\n",
      "\u001b[1;3;38;5;200mThought: I can answer without using any more tools. I'll use the user's language to answer.\n",
      "Answer: In the first five minutes of the video, there is a sense of urgency as someone is trying to stop a crane, indicating that time is critical. The phrase \"He has exactly five minutes left!\" suggests that there is a countdown or a deadline that needs to be met.\n",
      "\u001b[0m**********\n",
      "Trace: chat\n",
      "    |_agent_step -> 4.670294 seconds\n",
      "      |_llm -> 1.141642 seconds\n",
      "      |_function_call -> 2.049681 seconds\n",
      "        |_query -> 2.049365 seconds\n",
      "          |_retrieve -> 0.405702 seconds\n",
      "            |_embedding -> 0.399868 seconds\n",
      "          |_synthesize -> 1.643 seconds\n",
      "            |_templating -> 1.7e-05 seconds\n",
      "            |_llm -> 1.637989 seconds\n",
      "      |_llm -> 1.467608 seconds\n",
      "**********\n"
     ]
    }
   ],
   "source": [
    "response = react_agent.chat(\"what happended from first 5 minutes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "45b89a04-cab6-4940-b4fb-9ec108fb4e52",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Running step 87867bad-292a-4c80-956c-304f7211e604. Step input: Did he win the prize?\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "LLM Prompt Token Usage: 599\n",
      "LLM Completion Token Usage: 51\n",
      "** Messages: **\n",
      "system: You are designed to help with a variety of tasks, from answering questions to providing summaries to other types of analyses.\n",
      "\n",
      "## Tools\n",
      "\n",
      "You have access to a wide variety of tools. You are responsible for using the tools in any sequence you deem appropriate to complete the task at hand.\n",
      "This may require breaking the task into subtasks and using different tools to complete each subtask.\n",
      "\n",
      "You have access to the following tools:\n",
      "> Tool Name: transcript_tool\n",
      "Tool Description: answer questions related to audio transcripts, conversations, spoken content\n",
      "Tool Args: {\"type\": \"object\", \"properties\": {\"input\": {\"title\": \"Input\", \"type\": \"string\"}}, \"required\": [\"input\"]}\n",
      "\n",
      "> Tool Name: scene_tool\n",
      "Tool Description: answer questions related to scene description content\n",
      "Tool Args: {\"type\": \"object\", \"properties\": {\"input\": {\"title\": \"Input\", \"type\": \"string\"}}, \"required\": [\"input\"]}\n",
      "\n",
      "\n",
      "Here is some context to help you answer the question and plan:\n",
      "Your are video analysis expert, you can answer question related to poken content or visual scene descriptions.Focus on accurately understanding the context, intent, and nuances of the spoken content and scene description content. If a query asks for details not mentioned in the content, indicate that the information is not available.\n",
      "\n",
      "\n",
      "## Output Format\n",
      "\n",
      "Please answer in the same language as the question and use the following format:\n",
      "\n",
      "```\n",
      "Thought: The current language of the user is: (user's language). I need to use a tool to help me answer the question.\n",
      "Action: tool name (one of transcript_tool, scene_tool) if using a tool.\n",
      "Action Input: the input to the tool, in a JSON format representing the kwargs (e.g. {\"input\": \"hello world\", \"num_beams\": 5})\n",
      "```\n",
      "\n",
      "Please ALWAYS start with a Thought.\n",
      "\n",
      "NEVER surround your response with markdown code markers. You may use code markers within your response if you need to.\n",
      "\n",
      "Please use a valid JSON format for the Action Input. Do NOT do this {'input': 'hello world', 'num_beams': 5}.\n",
      "\n",
      "If this format is used, the user will respond in the following format:\n",
      "\n",
      "```\n",
      "Observation: tool response\n",
      "```\n",
      "\n",
      "You should keep repeating the above format till you have enough information to answer the question without using any more tools. At that point, you MUST respond in the one of the following two formats:\n",
      "\n",
      "```\n",
      "Thought: I can answer without using any more tools. I'll use the user's language to answer\n",
      "Answer: [your answer here (In the same language as the user's question)]\n",
      "```\n",
      "\n",
      "```\n",
      "Thought: I cannot answer the question with the provided tools.\n",
      "Answer: [your answer here (In the same language as the user's question)]\n",
      "```\n",
      "\n",
      "## Current Conversation\n",
      "\n",
      "Below is the current conversation consisting of interleaving human and assistant messages.\n",
      "\n",
      "user: Did he win the prize?\n",
      "**************************************************\n",
      "** Response: **\n",
      "assistant: Thought: The current language of the user is: English. I need more context to determine who \"he\" is and what prize is being referred to. \n",
      "Action: transcript_tool\n",
      "Action Input: {\"input\": \"Did he win the prize?\"}\n",
      "**************************************************\n",
      "\n",
      "\n",
      "\u001b[1;3;38;5;200mThought: The current language of the user is: English. I need more context to determine who \"he\" is and what prize is being referred to.\n",
      "Action: transcript_tool\n",
      "Action Input: {'input': 'Did he win the prize?'}\n",
      "\u001b[0mINFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Embedding Token Usage: 6\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "LLM Prompt Token Usage: 290\n",
      "LLM Completion Token Usage: 7\n",
      "** Messages: **\n",
      "system: You are an expert Q&A system that is trusted around the world.\n",
      "Always answer the query using the provided context information, and not prior knowledge.\n",
      "Some rules to follow:\n",
      "1. Never directly reference the given context in your answer.\n",
      "2. Avoid statements like 'Based on the context, ...' or 'The context information ...' or anything along those lines.\n",
      "user: Context information is below.\n",
      "---------------------\n",
      "start: 486.739990234375\n",
      "end: 489.739990234375\n",
      "\n",
      " You got it. He just did it. He got all four. He did it.\n",
      "\n",
      "start: 584.3800048828125\n",
      "end: 586.3800048828125\n",
      "\n",
      " And after he won with 19 seconds left,\n",
      "\n",
      "start: 389.260009765625\n",
      "end: 392.260009765625\n",
      "\n",
      " I actually don't help him. Well, let's see if he's smart enough to win the money.\n",
      "\n",
      "start: 442.5799865722656\n",
      "end: 445.5799865722656\n",
      "\n",
      " He did it. Other side. Other side.\n",
      "\n",
      "start: 588.3800048828125\n",
      "end: 590.3800048828125\n",
      "\n",
      " and asked what he was going to spend it on.\n",
      "---------------------\n",
      "Given the context information and not prior knowledge, answer the query.\n",
      "Query: Did he win the prize?\n",
      "Answer: \n",
      "**************************************************\n",
      "** Response: **\n",
      "assistant: Yes, he won the prize.\n",
      "**************************************************\n",
      "\n",
      "\n",
      "\u001b[1;3;34mObservation: Yes, he won the prize.\n",
      "\u001b[0m> Running step 94618fc9-ad7a-4105-853d-85ddbea6f44f. Step input: None\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "LLM Prompt Token Usage: 666\n",
      "LLM Completion Token Usage: 28\n",
      "** Messages: **\n",
      "system: You are designed to help with a variety of tasks, from answering questions to providing summaries to other types of analyses.\n",
      "\n",
      "## Tools\n",
      "\n",
      "You have access to a wide variety of tools. You are responsible for using the tools in any sequence you deem appropriate to complete the task at hand.\n",
      "This may require breaking the task into subtasks and using different tools to complete each subtask.\n",
      "\n",
      "You have access to the following tools:\n",
      "> Tool Name: transcript_tool\n",
      "Tool Description: answer questions related to audio transcripts, conversations, spoken content\n",
      "Tool Args: {\"type\": \"object\", \"properties\": {\"input\": {\"title\": \"Input\", \"type\": \"string\"}}, \"required\": [\"input\"]}\n",
      "\n",
      "> Tool Name: scene_tool\n",
      "Tool Description: answer questions related to scene description content\n",
      "Tool Args: {\"type\": \"object\", \"properties\": {\"input\": {\"title\": \"Input\", \"type\": \"string\"}}, \"required\": [\"input\"]}\n",
      "\n",
      "\n",
      "Here is some context to help you answer the question and plan:\n",
      "Your are video analysis expert, you can answer question related to poken content or visual scene descriptions.Focus on accurately understanding the context, intent, and nuances of the spoken content and scene description content. If a query asks for details not mentioned in the content, indicate that the information is not available.\n",
      "\n",
      "\n",
      "## Output Format\n",
      "\n",
      "Please answer in the same language as the question and use the following format:\n",
      "\n",
      "```\n",
      "Thought: The current language of the user is: (user's language). I need to use a tool to help me answer the question.\n",
      "Action: tool name (one of transcript_tool, scene_tool) if using a tool.\n",
      "Action Input: the input to the tool, in a JSON format representing the kwargs (e.g. {\"input\": \"hello world\", \"num_beams\": 5})\n",
      "```\n",
      "\n",
      "Please ALWAYS start with a Thought.\n",
      "\n",
      "NEVER surround your response with markdown code markers. You may use code markers within your response if you need to.\n",
      "\n",
      "Please use a valid JSON format for the Action Input. Do NOT do this {'input': 'hello world', 'num_beams': 5}.\n",
      "\n",
      "If this format is used, the user will respond in the following format:\n",
      "\n",
      "```\n",
      "Observation: tool response\n",
      "```\n",
      "\n",
      "You should keep repeating the above format till you have enough information to answer the question without using any more tools. At that point, you MUST respond in the one of the following two formats:\n",
      "\n",
      "```\n",
      "Thought: I can answer without using any more tools. I'll use the user's language to answer\n",
      "Answer: [your answer here (In the same language as the user's question)]\n",
      "```\n",
      "\n",
      "```\n",
      "Thought: I cannot answer the question with the provided tools.\n",
      "Answer: [your answer here (In the same language as the user's question)]\n",
      "```\n",
      "\n",
      "## Current Conversation\n",
      "\n",
      "Below is the current conversation consisting of interleaving human and assistant messages.\n",
      "\n",
      "user: Did he win the prize?\n",
      "assistant: Thought: The current language of the user is: English. I need more context to determine who \"he\" is and what prize is being referred to.\n",
      "Action: transcript_tool\n",
      "Action Input: {'input': 'Did he win the prize?'}\n",
      "user: Observation: Yes, he won the prize.\n",
      "**************************************************\n",
      "** Response: **\n",
      "assistant: Thought: I can answer without using any more tools. I'll use the user's language to answer.\n",
      "Answer: Yes, he won the prize.\n",
      "**************************************************\n",
      "\n",
      "\n",
      "\u001b[1;3;38;5;200mThought: I can answer without using any more tools. I'll use the user's language to answer.\n",
      "Answer: Yes, he won the prize.\n",
      "\u001b[0m**********\n",
      "Trace: query\n",
      "    |_agent_step -> 3.61307 seconds\n",
      "      |_llm -> 1.464962 seconds\n",
      "      |_function_call -> 1.269464 seconds\n",
      "        |_query -> 1.268967 seconds\n",
      "          |_retrieve -> 0.408993 seconds\n",
      "            |_embedding -> 0.38814 seconds\n",
      "          |_synthesize -> 0.859115 seconds\n",
      "            |_templating -> 2.4e-05 seconds\n",
      "            |_llm -> 0.853107 seconds\n",
      "      |_llm -> 0.869373 seconds\n",
      "**********\n"
     ]
    }
   ],
   "source": [
    "response = react_agent.query(\"Did he win the prize?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "7171aab2-297f-4cfe-be76-683634afb82c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Running step 2ae0af50-99bb-4b4e-a908-47891f51ac33. Step input: Tell me about the winning scene\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "LLM Prompt Token Usage: 599\n",
      "LLM Completion Token Usage: 40\n",
      "** Messages: **\n",
      "system: You are designed to help with a variety of tasks, from answering questions to providing summaries to other types of analyses.\n",
      "\n",
      "## Tools\n",
      "\n",
      "You have access to a wide variety of tools. You are responsible for using the tools in any sequence you deem appropriate to complete the task at hand.\n",
      "This may require breaking the task into subtasks and using different tools to complete each subtask.\n",
      "\n",
      "You have access to the following tools:\n",
      "> Tool Name: transcript_tool\n",
      "Tool Description: answer questions related to audio transcripts, conversations, spoken content\n",
      "Tool Args: {\"type\": \"object\", \"properties\": {\"input\": {\"title\": \"Input\", \"type\": \"string\"}}, \"required\": [\"input\"]}\n",
      "\n",
      "> Tool Name: scene_tool\n",
      "Tool Description: answer questions related to scene description content\n",
      "Tool Args: {\"type\": \"object\", \"properties\": {\"input\": {\"title\": \"Input\", \"type\": \"string\"}}, \"required\": [\"input\"]}\n",
      "\n",
      "\n",
      "Here is some context to help you answer the question and plan:\n",
      "Your are video analysis expert, you can answer question related to poken content or visual scene descriptions.Focus on accurately understanding the context, intent, and nuances of the spoken content and scene description content. If a query asks for details not mentioned in the content, indicate that the information is not available.\n",
      "\n",
      "\n",
      "## Output Format\n",
      "\n",
      "Please answer in the same language as the question and use the following format:\n",
      "\n",
      "```\n",
      "Thought: The current language of the user is: (user's language). I need to use a tool to help me answer the question.\n",
      "Action: tool name (one of transcript_tool, scene_tool) if using a tool.\n",
      "Action Input: the input to the tool, in a JSON format representing the kwargs (e.g. {\"input\": \"hello world\", \"num_beams\": 5})\n",
      "```\n",
      "\n",
      "Please ALWAYS start with a Thought.\n",
      "\n",
      "NEVER surround your response with markdown code markers. You may use code markers within your response if you need to.\n",
      "\n",
      "Please use a valid JSON format for the Action Input. Do NOT do this {'input': 'hello world', 'num_beams': 5}.\n",
      "\n",
      "If this format is used, the user will respond in the following format:\n",
      "\n",
      "```\n",
      "Observation: tool response\n",
      "```\n",
      "\n",
      "You should keep repeating the above format till you have enough information to answer the question without using any more tools. At that point, you MUST respond in the one of the following two formats:\n",
      "\n",
      "```\n",
      "Thought: I can answer without using any more tools. I'll use the user's language to answer\n",
      "Answer: [your answer here (In the same language as the user's question)]\n",
      "```\n",
      "\n",
      "```\n",
      "Thought: I cannot answer the question with the provided tools.\n",
      "Answer: [your answer here (In the same language as the user's question)]\n",
      "```\n",
      "\n",
      "## Current Conversation\n",
      "\n",
      "Below is the current conversation consisting of interleaving human and assistant messages.\n",
      "\n",
      "user: Tell me about the winning scene\n",
      "**************************************************\n",
      "** Response: **\n",
      "assistant: Thought: The current language of the user is: English. I need to use a tool to help me answer the question.\n",
      "Action: scene_tool\n",
      "Action Input: {\"input\": \"winning scene\"}\n",
      "**************************************************\n",
      "\n",
      "\n",
      "\u001b[1;3;38;5;200mThought: The current language of the user is: English. I need to use a tool to help me answer the question.\n",
      "Action: scene_tool\n",
      "Action Input: {'input': 'winning scene'}\n",
      "\u001b[0m\u001b[1;3;34mObservation: Error: 'VectorStoreIndex' object has no attribute 'query'\n",
      "\u001b[0m> Running step 844499ca-bd8b-454f-ac68-5e1e65a51e11. Step input: None\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "LLM Prompt Token Usage: 663\n",
      "LLM Completion Token Usage: 62\n",
      "** Messages: **\n",
      "system: You are designed to help with a variety of tasks, from answering questions to providing summaries to other types of analyses.\n",
      "\n",
      "## Tools\n",
      "\n",
      "You have access to a wide variety of tools. You are responsible for using the tools in any sequence you deem appropriate to complete the task at hand.\n",
      "This may require breaking the task into subtasks and using different tools to complete each subtask.\n",
      "\n",
      "You have access to the following tools:\n",
      "> Tool Name: transcript_tool\n",
      "Tool Description: answer questions related to audio transcripts, conversations, spoken content\n",
      "Tool Args: {\"type\": \"object\", \"properties\": {\"input\": {\"title\": \"Input\", \"type\": \"string\"}}, \"required\": [\"input\"]}\n",
      "\n",
      "> Tool Name: scene_tool\n",
      "Tool Description: answer questions related to scene description content\n",
      "Tool Args: {\"type\": \"object\", \"properties\": {\"input\": {\"title\": \"Input\", \"type\": \"string\"}}, \"required\": [\"input\"]}\n",
      "\n",
      "\n",
      "Here is some context to help you answer the question and plan:\n",
      "Your are video analysis expert, you can answer question related to poken content or visual scene descriptions.Focus on accurately understanding the context, intent, and nuances of the spoken content and scene description content. If a query asks for details not mentioned in the content, indicate that the information is not available.\n",
      "\n",
      "\n",
      "## Output Format\n",
      "\n",
      "Please answer in the same language as the question and use the following format:\n",
      "\n",
      "```\n",
      "Thought: The current language of the user is: (user's language). I need to use a tool to help me answer the question.\n",
      "Action: tool name (one of transcript_tool, scene_tool) if using a tool.\n",
      "Action Input: the input to the tool, in a JSON format representing the kwargs (e.g. {\"input\": \"hello world\", \"num_beams\": 5})\n",
      "```\n",
      "\n",
      "Please ALWAYS start with a Thought.\n",
      "\n",
      "NEVER surround your response with markdown code markers. You may use code markers within your response if you need to.\n",
      "\n",
      "Please use a valid JSON format for the Action Input. Do NOT do this {'input': 'hello world', 'num_beams': 5}.\n",
      "\n",
      "If this format is used, the user will respond in the following format:\n",
      "\n",
      "```\n",
      "Observation: tool response\n",
      "```\n",
      "\n",
      "You should keep repeating the above format till you have enough information to answer the question without using any more tools. At that point, you MUST respond in the one of the following two formats:\n",
      "\n",
      "```\n",
      "Thought: I can answer without using any more tools. I'll use the user's language to answer\n",
      "Answer: [your answer here (In the same language as the user's question)]\n",
      "```\n",
      "\n",
      "```\n",
      "Thought: I cannot answer the question with the provided tools.\n",
      "Answer: [your answer here (In the same language as the user's question)]\n",
      "```\n",
      "\n",
      "## Current Conversation\n",
      "\n",
      "Below is the current conversation consisting of interleaving human and assistant messages.\n",
      "\n",
      "user: Tell me about the winning scene\n",
      "assistant: Thought: The current language of the user is: English. I need to use a tool to help me answer the question.\n",
      "Action: scene_tool\n",
      "Action Input: {'input': 'winning scene'}\n",
      "user: Observation: Error: 'VectorStoreIndex' object has no attribute 'query'\n",
      "**************************************************\n",
      "** Response: **\n",
      "assistant: Thought: It seems there was an error when trying to retrieve information about the winning scene. I will attempt to gather more context about what is meant by \"winning scene\" to provide a better answer.\n",
      "Action: scene_tool\n",
      "Action Input: {'input': 'describe a winning scene in a film or story'}\n",
      "**************************************************\n",
      "\n",
      "\n",
      "\u001b[1;3;38;5;200mThought: It seems there was an error when trying to retrieve information about the winning scene. I will attempt to gather more context about what is meant by \"winning scene\" to provide a better answer.\n",
      "Action: scene_tool\n",
      "Action Input: {'input': 'describe a winning scene in a film or story'}\n",
      "\u001b[0m\u001b[1;3;34mObservation: Error: 'VectorStoreIndex' object has no attribute 'query'\n",
      "\u001b[0m> Running step 504eb8f5-1513-4462-9b4f-602db4ecdaaa. Step input: None\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "LLM Prompt Token Usage: 749\n",
      "LLM Completion Token Usage: 128\n",
      "** Messages: **\n",
      "system: You are designed to help with a variety of tasks, from answering questions to providing summaries to other types of analyses.\n",
      "\n",
      "## Tools\n",
      "\n",
      "You have access to a wide variety of tools. You are responsible for using the tools in any sequence you deem appropriate to complete the task at hand.\n",
      "This may require breaking the task into subtasks and using different tools to complete each subtask.\n",
      "\n",
      "You have access to the following tools:\n",
      "> Tool Name: transcript_tool\n",
      "Tool Description: answer questions related to audio transcripts, conversations, spoken content\n",
      "Tool Args: {\"type\": \"object\", \"properties\": {\"input\": {\"title\": \"Input\", \"type\": \"string\"}}, \"required\": [\"input\"]}\n",
      "\n",
      "> Tool Name: scene_tool\n",
      "Tool Description: answer questions related to scene description content\n",
      "Tool Args: {\"type\": \"object\", \"properties\": {\"input\": {\"title\": \"Input\", \"type\": \"string\"}}, \"required\": [\"input\"]}\n",
      "\n",
      "\n",
      "Here is some context to help you answer the question and plan:\n",
      "Your are video analysis expert, you can answer question related to poken content or visual scene descriptions.Focus on accurately understanding the context, intent, and nuances of the spoken content and scene description content. If a query asks for details not mentioned in the content, indicate that the information is not available.\n",
      "\n",
      "\n",
      "## Output Format\n",
      "\n",
      "Please answer in the same language as the question and use the following format:\n",
      "\n",
      "```\n",
      "Thought: The current language of the user is: (user's language). I need to use a tool to help me answer the question.\n",
      "Action: tool name (one of transcript_tool, scene_tool) if using a tool.\n",
      "Action Input: the input to the tool, in a JSON format representing the kwargs (e.g. {\"input\": \"hello world\", \"num_beams\": 5})\n",
      "```\n",
      "\n",
      "Please ALWAYS start with a Thought.\n",
      "\n",
      "NEVER surround your response with markdown code markers. You may use code markers within your response if you need to.\n",
      "\n",
      "Please use a valid JSON format for the Action Input. Do NOT do this {'input': 'hello world', 'num_beams': 5}.\n",
      "\n",
      "If this format is used, the user will respond in the following format:\n",
      "\n",
      "```\n",
      "Observation: tool response\n",
      "```\n",
      "\n",
      "You should keep repeating the above format till you have enough information to answer the question without using any more tools. At that point, you MUST respond in the one of the following two formats:\n",
      "\n",
      "```\n",
      "Thought: I can answer without using any more tools. I'll use the user's language to answer\n",
      "Answer: [your answer here (In the same language as the user's question)]\n",
      "```\n",
      "\n",
      "```\n",
      "Thought: I cannot answer the question with the provided tools.\n",
      "Answer: [your answer here (In the same language as the user's question)]\n",
      "```\n",
      "\n",
      "## Current Conversation\n",
      "\n",
      "Below is the current conversation consisting of interleaving human and assistant messages.\n",
      "\n",
      "user: Tell me about the winning scene\n",
      "assistant: Thought: The current language of the user is: English. I need to use a tool to help me answer the question.\n",
      "Action: scene_tool\n",
      "Action Input: {'input': 'winning scene'}\n",
      "user: Observation: Error: 'VectorStoreIndex' object has no attribute 'query'\n",
      "assistant: Thought: It seems there was an error when trying to retrieve information about the winning scene. I will attempt to gather more context about what is meant by \"winning scene\" to provide a better answer.\n",
      "Action: scene_tool\n",
      "Action Input: {'input': 'describe a winning scene in a film or story'}\n",
      "user: Observation: Error: 'VectorStoreIndex' object has no attribute 'query'\n",
      "**************************************************\n",
      "** Response: **\n",
      "assistant: Thought: It appears that there are persistent issues with retrieving information about the winning scene using the tools available. I will try to provide a general description of what a winning scene typically entails in films or stories based on common knowledge.\n",
      "Answer: A winning scene in a film or story often refers to a climactic moment where the protagonist achieves a significant victory or overcomes a major obstacle. This scene is usually emotionally charged, showcasing the character's growth, determination, and the culmination of their journey. It may involve a dramatic confrontation, a heartfelt revelation, or a triumphant celebration, often accompanied by uplifting music and visuals that enhance the emotional impact.\n",
      "**************************************************\n",
      "\n",
      "\n",
      "\u001b[1;3;38;5;200mThought: It appears that there are persistent issues with retrieving information about the winning scene using the tools available. I will try to provide a general description of what a winning scene typically entails in films or stories based on common knowledge.\n",
      "Answer: A winning scene in a film or story often refers to a climactic moment where the protagonist achieves a significant victory or overcomes a major obstacle. This scene is usually emotionally charged, showcasing the character's growth, determination, and the culmination of their journey. It may involve a dramatic confrontation, a heartfelt revelation, or a triumphant celebration, often accompanied by uplifting music and visuals that enhance the emotional impact.\n",
      "\u001b[0m**********\n",
      "Trace: query\n",
      "    |_agent_step -> 3.801406 seconds\n",
      "      |_llm -> 1.016944 seconds\n",
      "      |_function_call -> 0.000352 seconds\n",
      "      |_llm -> 1.427641 seconds\n",
      "      |_function_call -> 0.000174 seconds\n",
      "      |_llm -> 1.345282 seconds\n",
      "**********\n"
     ]
    }
   ],
   "source": [
    "response = react_agent.query(\"Tell me about the winning scene\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a928aec2-82fa-4ce5-a852-2a58cfc23542",
   "metadata": {},
   "source": [
    "### OpenAI agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "d9145068-a5f4-4bd2-bf21-98cd58f70670",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.agent.openai import OpenAIAgentWorker, OpenAIAgent\n",
    "from llama_index.core.tools import FunctionTool, QueryEngineTool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fc4d16f-da07-44b2-9516-6f621b4a001d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "cdf25db7-5533-4b0c-88cb-b203907a2aa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "openai_agent = OpenAIAgent.from_tools(\n",
    "    [transcipt_tool, scene_tool],\n",
    "    system_prompt=agent_context,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c035ceaf-e63d-4660-9f39-0d0b34c16179",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added user message to memory: What is the prize?\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "LLM Prompt Token Usage: 141\n",
      "LLM Completion Token Usage: 22\n",
      "** Messages: **\n",
      "system: Your are video analysis expert, you can answer question related to poken content or visual scene descriptions.Focus on accurately understanding the context, intent, and nuances of the spoken content and scene description content. If a query asks for details not mentioned in the content, indicate that the information is not available.\n",
      "user: What is the prize?\n",
      "**************************************************\n",
      "** Response: **\n",
      "assistant: The information about the prize is not available. Please provide more context or details for a more specific inquiry.\n",
      "**************************************************\n",
      "\n",
      "\n",
      "**********\n",
      "Trace: query\n",
      "    |_agent_step -> 0.91547 seconds\n",
      "      |_llm -> 0.912122 seconds\n",
      "**********\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Response(response='The information about the prize is not available. Please provide more context or details for a more specific inquiry.', source_nodes=[], metadata=None)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "openai_agent.query(\"What is the prize?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56312903-b6bd-4c40-bbbb-d3f861463690",
   "metadata": {},
   "source": [
    "### Agent runner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "50209f25-f558-4b69-a9a1-55f00f00f4bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.agent import FunctionCallingAgentWorker\n",
    "from llama_index.core.agent import AgentRunner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8b3ebca3-e652-41ea-8c3c-79fb16f274ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_worker = FunctionCallingAgentWorker.from_tools(\n",
    "    [transcipt_tool, scene_tool],\n",
    "    system_prompt=agent_context,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a421d562-2905-4333-b921-be67fc725585",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = AgentRunner(agent_worker, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "cf7b8681-cdab-420c-b370-e4b14b8ebaf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Running step b40b17e1-1e0d-40aa-9483-a771c969393a. Step input: What is the prize?\n",
      "Added user message to memory: What is the prize?\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "LLM Prompt Token Usage: 141\n",
      "LLM Completion Token Usage: 21\n",
      "** Messages: **\n",
      "system: Your are video analysis expert, you can answer question related to poken content or visual scene descriptions.Focus on accurately understanding the context, intent, and nuances of the spoken content and scene description content. If a query asks for details not mentioned in the content, indicate that the information is not available.\n",
      "user: What is the prize?\n",
      "**************************************************\n",
      "** Response: **\n",
      "assistant: The information about the prize is not available. Please provide more context or details for a specific inquiry.\n",
      "**************************************************\n",
      "\n",
      "\n",
      "=== LLM Response ===\n",
      "The information about the prize is not available. Please provide more context or details for a specific inquiry.\n",
      "**********\n",
      "Trace: query\n",
      "    |_agent_step -> 1.625037 seconds\n",
      "      |_llm -> 1.616643 seconds\n",
      "**********\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Response(response='The information about the prize is not available. Please provide more context or details for a specific inquiry.', source_nodes=[], metadata=None)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.query(\"What is the prize?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1c96b6f-2818-491f-a76a-9147981c244a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be01ece1-afb8-4ad0-b876-8449c87614e4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm-py310",
   "language": "python",
   "name": "llm-py310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
